{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import trange\n",
    "import random\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FILE = 'ml-1m.zip'\n",
    "DATA_URL = 'https://files.grouplens.org/datasets/movielens/'\\\n",
    "            '{}'.format(ZIP_FILE)\n",
    "DATA_PATH = './ml-1m/ratings.dat'\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    wget.download(DATA_URL)\n",
    "    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовка формата для pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemRatingDataset(Dataset):\n",
    "    def __init__(self, user:list, item:list, rating:list):\n",
    "        super(UserItemRatingDataset, self).__init__()\n",
    "        \n",
    "        self.user = torch.tensor(user, dtype=torch.long)\n",
    "        self.item = torch.tensor(item, dtype=torch.long)\n",
    "        self.target = torch.tensor(rating, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user[idx], self.item[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFData(object):\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 num_negatives,\n",
    "                 num_negatives_test,\n",
    "                 batch_size:int):\n",
    "        self.ratings = ratings\n",
    "        self.num_negatives = num_negatives\n",
    "        self.num_negatives_test = num_negatives_test\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.preprocess_ratings = self._reindex(self.ratings)\n",
    "        self.user_pool = set(self.ratings['user_id'].unique())\n",
    "        self.item_pool = set(self.ratings['item_id'].unique())\n",
    "\n",
    "        self.train_ratings, self.test_ratings =\\\n",
    "            self._leave_one_out(self.preprocess_ratings)\n",
    "        self.negatives =\\\n",
    "            self._negative_sampling(self.preprocess_ratings)\n",
    "        \n",
    "    def _reindex(self, ratings):\n",
    "        user = list(ratings['user_id'].drop_duplicates())\n",
    "        self.user2id = {w: i for i, w in enumerate(user)}\n",
    "\n",
    "        item = list(ratings['item_id'].drop_duplicates())\n",
    "        self.item2id = {w: i for i, w in enumerate(item)}\n",
    "\n",
    "        ratings['user_id'] = ratings['user_id'].\\\n",
    "            apply(lambda x: self.user2id[x])\n",
    "        ratings['item_id'] = ratings['item_id'].\\\n",
    "            apply(lambda x: self.item2id[x])\n",
    "        ratings['rating'] = ratings['rating'].\\\n",
    "            apply(lambda x: float(x > 0))\n",
    "        return ratings\n",
    "        \n",
    "    def _leave_one_out(self, ratings):\n",
    "        ratings['rank_latest'] =\\\n",
    "            ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=True)\n",
    "        test = ratings.loc[ratings['rank_latest'] == 1]\n",
    "        train = ratings.loc[ratings['rank_latest'] > 1]\n",
    "        return train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "    def _negative_sampling(self, ratings):\n",
    "        interact_status = (\n",
    "            ratings.groupby('user_id')['item_id']\n",
    "            .apply(set)\n",
    "            .reset_index()\n",
    "            .rename(columns={'item_id': 'interacted_items'})\n",
    "        )\n",
    "        interact_status['negative_items'] = (\n",
    "            interact_status['interacted_items'].\\\n",
    "                apply(lambda x: self.item_pool - x)\n",
    "        )\n",
    "        interact_status['negative_samples'] = (\n",
    "            interact_status['negative_items'].\\\n",
    "                apply(lambda x: random.sample(x, self.num_negatives_test))\n",
    "        )\n",
    "        return interact_status[['user_id', 'negative_items', 'negative_samples']]\n",
    "    \n",
    "    def get_train_instance(self):\n",
    "        users, items, ratings = [], [], []\n",
    "        train_ratings = pd.merge(self.train_ratings, \n",
    "                                 self.negatives[['user_id', 'negative_items']],\n",
    "                                 on='user_id')\n",
    "        train_ratings['negatives'] = (\n",
    "            train_ratings['negative_items'].\\\n",
    "                apply(lambda x: random.sample(x, self.num_negatives))\n",
    "        )\n",
    "\n",
    "        for row in train_ratings.itertuples():\n",
    "            users.append(int(row.user_id))\n",
    "            items.append(int(row.item_id))\n",
    "            ratings.append(float(row.rating))\n",
    "            \n",
    "        dataset = UserItemRatingDataset(user=users,\n",
    "                                        item=items,\n",
    "                                        rating=ratings)\n",
    "        return DataLoader(dataset,\n",
    "                         batch_size=self.batch_size,\n",
    "                         shuffle=True, num_workers=4)\n",
    "        \n",
    "    def get_test_instance(self):\n",
    "        users, items, ratings = [], [], []\n",
    "        test_ratings = pd.merge(self.test_ratings, \n",
    "                                 self.negatives[['user_id', 'negative_items']],\n",
    "                                 on='user_id')\n",
    "\n",
    "        for row in test_ratings.itertuples():\n",
    "            users.append(int(row.user_id))\n",
    "            items.append(int(row.item_id))\n",
    "            ratings.append(float(row.rating))\n",
    "            \n",
    "        dataset = UserItemRatingDataset(user=users,\n",
    "                                        item=items,\n",
    "                                        rating=ratings)\n",
    "        return DataLoader(dataset,\n",
    "                            batch_size=self.batch_size,\n",
    "                            shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_1m = pd.read_csv(DATA_PATH, sep='::', engine='python',\n",
    "                    names=['user_id', 'item_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ml_1m['user_id'].unique()+1\n",
    "num_items = ml_1m['item_id'].unique()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NCFData(ml_1m, num_negatives=4,\n",
    "           num_negatives_test=100, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ndcg(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "def mrr(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item) + 1\n",
    "        return 1/index\n",
    "    return 0\n",
    "\n",
    "@torch.no_grad()\n",
    "def metrics(model, test_loader, top_k, device):\n",
    "    _hr, _ndcg, _mrr = [], [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        predictions = predictions.view(-1)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        ng_item = item[0].item()\n",
    "        _hr.append(hit(ng_item, recommends))\n",
    "        _ndcg.append(ndcg(ng_item, recommends))\n",
    "        _mrr.append(mrr(ng_item, recommends))\n",
    "    \n",
    "    return np.mean(_hr), np.mean(_ndcg), np.mean(_mrr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура (GMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=num_users, \n",
    "            embedding_dim=embedding_dim)\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=num_items,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.affine_output = nn.Linear(\n",
    "            in_features=embedding_dim,\n",
    "            out_features=1\n",
    "        )\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indeces):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indeces)\n",
    "        element_product = torch.mul(user_embedding,\n",
    "                                    item_embedding)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.activation(logits)\n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(model,\n",
    "                   optimizer,\n",
    "                   criterion,\n",
    "                   data,\n",
    "                   num_epoch):\n",
    "    loss_history = []\n",
    "    metrics_history = {'HR@10': [], 'NDCG@10': []}\n",
    "    test_loader = data.get_test_instance()\n",
    "    \n",
    "    for epoch in trange(num_epoch):\n",
    "        model.train()\n",
    "        \n",
    "        train_loader = data.get_train_instance()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(DEVICE)\n",
    "            item = item.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(user, item)\n",
    "            \n",
    "            loss = criterion(prediction.view(-1).to(torch.float64), \n",
    "                            label.to(torch.float64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        hr_i, ndcg_i, mrr_i = metrics(model, test_loader, 10, DEVICE)\n",
    "        metrics_history['HR@10'].append(hr_i)\n",
    "        metrics_history['NDCG@10'].append(ndcg_i)\n",
    "\n",
    "        print(f\"[Epoch {epoch}]| Loss: {loss.item():.5f}\\n\"\\\n",
    "              f\"HR@10: {hr_i:.3f}\\tMRR@10: {mrr_i:.3f}\\tNDCG@10: {ndcg_i:.3f} |\")\n",
    "\n",
    "    return loss_history, metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMF(num_users=len(num_users), num_items=len(num_items), embedding_dim=32)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4c55708c594b2d82c7654f79c6e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.03803\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 1]| Loss: 0.00439\n",
      "HR@10: 0.333\tMRR@10: 0.048\tNDCG@10: 0.111 |\n",
      "[Epoch 2]| Loss: 0.00103\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 3]| Loss: 0.00050\n",
      "HR@10: 0.333\tMRR@10: 0.111\tNDCG@10: 0.167 |\n",
      "[Epoch 4]| Loss: 0.00035\n",
      "HR@10: 0.333\tMRR@10: 0.037\tNDCG@10: 0.100 |\n",
      "[Epoch 5]| Loss: 0.00016\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 6]| Loss: 0.00017\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 7]| Loss: 0.00011\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 8]| Loss: 0.00007\n",
      "HR@10: 0.333\tMRR@10: 0.033\tNDCG@10: 0.096 |\n",
      "[Epoch 9]| Loss: 0.00003\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n"
     ]
    }
   ],
   "source": [
    "loss_history, metrics_history = train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim,\n",
    "                 layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embeddings_dim = embedding_dim\n",
    "        self.layers = layers\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=self.num_users,\n",
    "            embedding_dim=self.embeddings_dim\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=self.num_items,\n",
    "            embedding_dim=self.embeddings_dim\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.embeddings_dim * 2, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], layers[2])\n",
    "        self.fc4 = nn.Linear(layers[2], layers[3])\n",
    "        self.fc5 = nn.Linear(layers[3], layers[4])\n",
    "        self.fc6 = nn.Linear(layers[4], layers[5])\n",
    "\n",
    "        self.affine_output = nn.Linear(self.layers[-1], 1)\n",
    "        self.activation_layer = nn.ReLU()\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_concat = torch.cat((user_embedding,\n",
    "                                    item_embedding), -1)\n",
    "        layer1 = self.activation_layer(self.fc1(element_concat))\n",
    "        layer2 = self.activation_layer(self.fc2(layer1))\n",
    "        layer3 = self.activation_layer(self.fc3(layer2))\n",
    "        layer4 = self.activation_layer(self.fc4(layer3))\n",
    "        layer5 = self.activation_layer(self.fc5(layer4))\n",
    "        layer6 = self.activation_layer(self.fc6(layer5))\n",
    "\n",
    "        logits = self.affine_output(layer6)\n",
    "        rating = self.activation(logits)\n",
    "\n",
    "        return rating\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(num_users=len(num_users),\n",
    "            num_items=len(num_items),\n",
    "            embedding_dim=128,\n",
    "            layers=[128, 64, 32, 16, 8, 4])\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 128, 128]            773,120\n",
      "├─Embedding: 1-2                         [-1, 128, 128]            474,368\n",
      "├─Linear: 1-3                            [-1, 128, 128]            32,896\n",
      "├─ReLU: 1-4                              [-1, 128, 128]            --\n",
      "├─Linear: 1-5                            [-1, 128, 64]             8,256\n",
      "├─ReLU: 1-6                              [-1, 128, 64]             --\n",
      "├─Linear: 1-7                            [-1, 128, 32]             2,080\n",
      "├─ReLU: 1-8                              [-1, 128, 32]             --\n",
      "├─Linear: 1-9                            [-1, 128, 16]             528\n",
      "├─ReLU: 1-10                             [-1, 128, 16]             --\n",
      "├─Linear: 1-11                           [-1, 128, 8]              136\n",
      "├─ReLU: 1-12                             [-1, 128, 8]              --\n",
      "├─Linear: 1-13                           [-1, 128, 4]              36\n",
      "├─ReLU: 1-14                             [-1, 128, 4]              --\n",
      "├─Linear: 1-15                           [-1, 128, 1]              5\n",
      "├─Sigmoid: 1-16                          [-1, 128, 1]              --\n",
      "==========================================================================================\n",
      "Total params: 1,291,425\n",
      "Trainable params: 1,291,425\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.29\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.50\n",
      "Params size (MB): 4.93\n",
      "Estimated Total Size (MB): 5.42\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 128, 128]            773,120\n",
       "├─Embedding: 1-2                         [-1, 128, 128]            474,368\n",
       "├─Linear: 1-3                            [-1, 128, 128]            32,896\n",
       "├─ReLU: 1-4                              [-1, 128, 128]            --\n",
       "├─Linear: 1-5                            [-1, 128, 64]             8,256\n",
       "├─ReLU: 1-6                              [-1, 128, 64]             --\n",
       "├─Linear: 1-7                            [-1, 128, 32]             2,080\n",
       "├─ReLU: 1-8                              [-1, 128, 32]             --\n",
       "├─Linear: 1-9                            [-1, 128, 16]             528\n",
       "├─ReLU: 1-10                             [-1, 128, 16]             --\n",
       "├─Linear: 1-11                           [-1, 128, 8]              136\n",
       "├─ReLU: 1-12                             [-1, 128, 8]              --\n",
       "├─Linear: 1-13                           [-1, 128, 4]              36\n",
       "├─ReLU: 1-14                             [-1, 128, 4]              --\n",
       "├─Linear: 1-15                           [-1, 128, 1]              5\n",
       "├─Sigmoid: 1-16                          [-1, 128, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 1,291,425\n",
       "Trainable params: 1,291,425\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.29\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.50\n",
       "Params size (MB): 4.93\n",
       "Estimated Total Size (MB): 5.42\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [(128,), (128,)], dtypes=[torch.long, torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85a68c958142aebd95342769056d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.00001\n",
      "HR@10: 0.333\tMRR@10: 0.167\tNDCG@10: 0.210 |\n",
      "[Epoch 1]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.667\tNDCG@10: 0.667 |\n",
      "[Epoch 2]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.114\tNDCG@10: 0.240 |\n",
      "[Epoch 3]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.167\tNDCG@10: 0.285 |\n",
      "[Epoch 4]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.144\tNDCG@10: 0.263 |\n",
      "[Epoch 5]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.200\tNDCG@10: 0.383 |\n",
      "[Epoch 6]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.089\tNDCG@10: 0.216 |\n",
      "[Epoch 7]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.079\tNDCG@10: 0.205 |\n",
      "[Epoch 8]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.089\tNDCG@10: 0.216 |\n",
      "[Epoch 9]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.103\tNDCG@10: 0.230 |\n"
     ]
    }
   ],
   "source": [
    "loss_history_mlp, metrics_history_mlp =\\\n",
    "    train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim,\n",
    "                 layers):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.layers = layers\n",
    "\n",
    "        self.embedding_user_mlp = nn.Embedding(\n",
    "            num_embeddings=self.num_users + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.embedding_item_mlp = nn.Embedding(\n",
    "            num_embeddings=self.num_items + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "\n",
    "        self.embedding_user_mf = nn.Embedding(\n",
    "            num_embeddings=self.num_users + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.embedding_item_mf = nn.Embedding(\n",
    "            num_embeddings=self.num_items + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim * 2, self.layers[0]),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[0], self.layers[1]),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[1], self.layers[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[2], self.layers[3])\n",
    "        )\n",
    "\n",
    "        self.affine_output = nn.Linear(\n",
    "            self.layers[-1] + self.embedding_dim, 1\n",
    "        )\n",
    "        self.activate = nn.Sigmoid()\n",
    "        \n",
    "        # nn.init.xavier_uniform_(self.embedding_user_mlp.weight)\n",
    "        # nn.init.xavier_uniform_(self.embedding_item_mlp.weight)\n",
    "\n",
    "        # nn.init.xavier_uniform_(self.embedding_user_mf.weight)\n",
    "        # nn.init.xavier_uniform_(self.embedding_item_mf.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n",
    "\n",
    "        user_embedding_mf = self.embedding_user_mf(user_indices)\n",
    "        item_embedding_mf = self.embedding_item_mf(item_indices)\n",
    "\n",
    "        element_product_mf = torch.mul(\n",
    "            user_embedding_mf,\n",
    "            item_embedding_mf\n",
    "        )\n",
    "\n",
    "        element_product_mlp = torch.cat(\n",
    "            (user_embedding_mlp, item_embedding_mlp), -1\n",
    "        )\n",
    "\n",
    "        layers = self.fc(element_product_mlp)\n",
    "\n",
    "        logits = self.affine_output(torch.cat(\n",
    "            (layers, element_product_mf), -1)\n",
    "        )\n",
    "        rating = self.activate(logits)\n",
    "\n",
    "        return rating\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(num_users=len(num_users),\n",
    "              num_items=len(num_items),\n",
    "              embedding_dim=128,\n",
    "              layers=[32, 16, 8, 4])\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 128, 128]            773,248\n",
      "├─Embedding: 1-2                         [-1, 128, 128]            474,496\n",
      "├─Embedding: 1-3                         [-1, 128, 128]            773,248\n",
      "├─Embedding: 1-4                         [-1, 128, 128]            474,496\n",
      "├─Sequential: 1-5                        [-1, 128, 4]              --\n",
      "|    └─Linear: 2-1                       [-1, 128, 32]             8,224\n",
      "|    └─Dropout: 2-2                      [-1, 128, 32]             --\n",
      "|    └─ReLU: 2-3                         [-1, 128, 32]             --\n",
      "|    └─Linear: 2-4                       [-1, 128, 16]             528\n",
      "|    └─Dropout: 2-5                      [-1, 128, 16]             --\n",
      "|    └─ReLU: 2-6                         [-1, 128, 16]             --\n",
      "|    └─Linear: 2-7                       [-1, 128, 8]              136\n",
      "|    └─ReLU: 2-8                         [-1, 128, 8]              --\n",
      "|    └─Linear: 2-9                       [-1, 128, 4]              36\n",
      "├─Linear: 1-6                            [-1, 128, 1]              133\n",
      "├─Sigmoid: 1-7                           [-1, 128, 1]              --\n",
      "==========================================================================================\n",
      "Total params: 2,504,545\n",
      "Trainable params: 2,504,545\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.56\n",
      "Params size (MB): 9.55\n",
      "Estimated Total Size (MB): 10.11\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 128, 128]            773,248\n",
       "├─Embedding: 1-2                         [-1, 128, 128]            474,496\n",
       "├─Embedding: 1-3                         [-1, 128, 128]            773,248\n",
       "├─Embedding: 1-4                         [-1, 128, 128]            474,496\n",
       "├─Sequential: 1-5                        [-1, 128, 4]              --\n",
       "|    └─Linear: 2-1                       [-1, 128, 32]             8,224\n",
       "|    └─Dropout: 2-2                      [-1, 128, 32]             --\n",
       "|    └─ReLU: 2-3                         [-1, 128, 32]             --\n",
       "|    └─Linear: 2-4                       [-1, 128, 16]             528\n",
       "|    └─Dropout: 2-5                      [-1, 128, 16]             --\n",
       "|    └─ReLU: 2-6                         [-1, 128, 16]             --\n",
       "|    └─Linear: 2-7                       [-1, 128, 8]              136\n",
       "|    └─ReLU: 2-8                         [-1, 128, 8]              --\n",
       "|    └─Linear: 2-9                       [-1, 128, 4]              36\n",
       "├─Linear: 1-6                            [-1, 128, 1]              133\n",
       "├─Sigmoid: 1-7                           [-1, 128, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 2,504,545\n",
       "Trainable params: 2,504,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.51\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.56\n",
       "Params size (MB): 9.55\n",
       "Estimated Total Size (MB): 10.11\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [(128,), (128,)], dtypes=[torch.long, torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3108917d8ddb413e89c13c346d504037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.00017\n",
      "HR@10: 0.333\tMRR@10: 0.056\tNDCG@10: 0.119 |\n",
      "[Epoch 1]| Loss: 0.00005\n",
      "HR@10: 0.667\tMRR@10: 0.095\tNDCG@10: 0.222 |\n",
      "[Epoch 2]| Loss: 0.00001\n",
      "HR@10: 1.000\tMRR@10: 0.145\tNDCG@10: 0.334 |\n",
      "[Epoch 3]| Loss: 0.00001\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 4]| Loss: 0.00002\n",
      "HR@10: 1.000\tMRR@10: 0.194\tNDCG@10: 0.377 |\n",
      "[Epoch 5]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.131\tNDCG@10: 0.321 |\n",
      "[Epoch 6]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.120\tNDCG@10: 0.311 |\n",
      "[Epoch 7]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 8]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 9]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n"
     ]
    }
   ],
   "source": [
    "loss_history_neumf, metrics_history_neumf =\\\n",
    "    train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
