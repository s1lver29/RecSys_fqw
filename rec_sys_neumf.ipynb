{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import trange\n",
    "import random\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FILE = 'ml-10m.zip'\n",
    "DATA_URL = 'https://files.grouplens.org/datasets/movielens/'\\\n",
    "            '{}'.format(ZIP_FILE)\n",
    "DATA_PATH = './ml-10M100K/ratings.dat'\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    wget.download(DATA_URL)\n",
    "    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep='::', engine='python',\n",
    "                    names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69878,) (10677,) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(df['user_id'].unique().shape, df['item_id'].unique().shape, df['rating'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000054 entries, 0 to 10000053\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   user_id    int64  \n",
      " 1   item_id    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 305.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df['user_id'].astype('uint32')\n",
    "df['item_id'] = df['item_id'].astype('uint16')\n",
    "df['rating'] = df['rating'].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000054 entries, 0 to 10000053\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   user_id    uint32 \n",
      " 1   item_id    uint16 \n",
      " 2   rating     float32\n",
      " 3   timestamp  int64  \n",
      "dtypes: float32(1), int64(1), uint16(1), uint32(1)\n",
      "memory usage: 171.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('./ml-10M100K/ratings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquet = pd.read_parquet('./ml-10M100K/ratings.parquet')\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(item_nefative: 0, user_negative: 0)\n"
     ]
    }
   ],
   "source": [
    "print('(item_nefative: {}, user_negative: {})'.format(\n",
    "df_parquet[df_parquet['item_id'] < 0].shape[0], df_parquet[df_parquet['user_id'] < 0].shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовка формата для pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemRatingDataset(Dataset):\n",
    "    def __init__(self, user:list, item:list, rating:list):\n",
    "        super(UserItemRatingDataset, self).__init__()\n",
    "        \n",
    "        self.user = torch.tensor(user, dtype=torch.long)\n",
    "        self.item = torch.tensor(item, dtype=torch.long)\n",
    "        self.target = torch.tensor(rating, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user[idx], self.item[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFData(object):\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 num_negatives,\n",
    "                 num_negatives_test,\n",
    "                 batch_size:int):\n",
    "        self.ratings = ratings\n",
    "        self.num_negatives = num_negatives\n",
    "        self.num_negatives_test = num_negatives_test\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.preprocess_ratings = self._reindex(self.ratings)\n",
    "        self.user_pool = set(self.ratings['user_id'].unique())\n",
    "        self.item_pool = set(self.ratings['item_id'].unique())\n",
    "\n",
    "        self.train_ratings, self.test_ratings =\\\n",
    "            self._leave_one_out(self.preprocess_ratings)\n",
    "        self.negatives =\\\n",
    "            self._negative_sampling(self.preprocess_ratings)\n",
    "        \n",
    "    def _reindex(self, ratings):\n",
    "        user = list(ratings['user_id'].drop_duplicates())\n",
    "        self.user2id = {w: i for i, w in enumerate(user)}\n",
    "\n",
    "        item = list(ratings['item_id'].drop_duplicates())\n",
    "        self.item2id = {w: i for i, w in enumerate(item)}\n",
    "\n",
    "        ratings['user_id'] = ratings['user_id'].\\\n",
    "            apply(lambda x: self.user2id[x])\n",
    "        ratings['item_id'] = ratings['item_id'].\\\n",
    "            apply(lambda x: self.item2id[x])\n",
    "        ratings['rating'] = ratings['rating'].\\\n",
    "            apply(lambda x: float(x > 0))\n",
    "        return ratings\n",
    "        \n",
    "    def _leave_one_out(self, ratings):\n",
    "        ratings['rank_latest'] =\\\n",
    "            ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=True)\n",
    "        test = ratings.loc[ratings['rank_latest'] == 1]\n",
    "        train = ratings.loc[ratings['rank_latest'] > 1]\n",
    "        return train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "    def _negative_sampling(self, ratings):\n",
    "        interact_status = (\n",
    "            ratings.groupby('user_id')['item_id']\n",
    "            .apply(set)\n",
    "            .reset_index()\n",
    "            .rename(columns={'item_id': 'interacted_items'})\n",
    "        )\n",
    "        interact_status['negative_items'] = (\n",
    "            interact_status['interacted_items'].\\\n",
    "                apply(lambda x: self.item_pool - x)\n",
    "        )\n",
    "        interact_status['negative_samples'] = (\n",
    "            interact_status['negative_items'].\\\n",
    "                apply(lambda x: random.sample(x, self.num_negatives_test))\n",
    "        )\n",
    "        return interact_status[['user_id', 'negative_items', 'negative_samples']]\n",
    "    \n",
    "    def get_train_instance(self):\n",
    "        users, items, ratings = [], [], []\n",
    "        train_ratings = pd.merge(self.train_ratings, \n",
    "                                 self.negatives[['user_id', 'negative_items']],\n",
    "                                 on='user_id')\n",
    "        train_ratings['negatives'] = (\n",
    "            train_ratings['negative_items'].\\\n",
    "                apply(lambda x: random.sample(x, self.num_negatives))\n",
    "        )\n",
    "\n",
    "        for row in train_ratings.itertuples():\n",
    "            users.append(int(row.user_id))\n",
    "            items.append(int(row.item_id))\n",
    "            ratings.append(float(row.rating))\n",
    "            \n",
    "        dataset = UserItemRatingDataset(user=users,\n",
    "                                        item=items,\n",
    "                                        rating=ratings)\n",
    "        return DataLoader(dataset,\n",
    "                         batch_size=self.batch_size,\n",
    "                         shuffle=True, num_workers=4)\n",
    "        \n",
    "    def get_test_instance(self):\n",
    "        users, items, ratings = [], [], []\n",
    "        test_ratings = pd.merge(self.test_ratings, \n",
    "                                 self.negatives[['user_id', 'negative_items']],\n",
    "                                 on='user_id')\n",
    "\n",
    "        for row in test_ratings.itertuples():\n",
    "            users.append(int(row.user_id))\n",
    "            items.append(int(row.item_id))\n",
    "            ratings.append(float(row.rating))\n",
    "            \n",
    "        dataset = UserItemRatingDataset(user=users,\n",
    "                                        item=items,\n",
    "                                        rating=ratings)\n",
    "        return DataLoader(dataset,\n",
    "                            batch_size=self.batch_size,\n",
    "                            shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_1m = pd.read_csv(DATA_PATH, sep='::', engine='python',\n",
    "#                     names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ml_10m = pd.read_parquet('./ml-10M100K/ratings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ml_10m['user_id'].unique()+1\n",
    "num_items = ml_10m['item_id'].unique()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data = NCFData(ml_10m, num_negatives=4,\n",
    "           num_negatives_test=100, batch_size=1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ndcg(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "def mrr(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item) + 1\n",
    "        return 1/index\n",
    "    return 0\n",
    "\n",
    "@torch.no_grad()\n",
    "def metrics(model, test_loader, top_k, device):\n",
    "    _hr, _ndcg, _mrr = [], [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        predictions = predictions.view(-1)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        ng_item = item[0].item()\n",
    "        _hr.append(hit(ng_item, recommends))\n",
    "        _ndcg.append(ndcg(ng_item, recommends))\n",
    "        _mrr.append(mrr(ng_item, recommends))\n",
    "    \n",
    "    return np.mean(_hr), np.mean(_ndcg), np.mean(_mrr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура (GMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=num_users, \n",
    "            embedding_dim=embedding_dim)\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=num_items,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "        self.affine_output = nn.Linear(\n",
    "            in_features=embedding_dim,\n",
    "            out_features=1\n",
    "        )\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indeces):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indeces)\n",
    "        element_product = torch.mul(user_embedding,\n",
    "                                    item_embedding)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.activation(logits)\n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(model,\n",
    "                   optimizer,\n",
    "                   criterion,\n",
    "                   data,\n",
    "                   num_epoch):\n",
    "    loss_history = []\n",
    "    metrics_history = {'HR@10': [], 'NDCG@10': []}\n",
    "    test_loader = data.get_test_instance()\n",
    "    \n",
    "    for epoch in trange(num_epoch):\n",
    "        model.train()\n",
    "        \n",
    "        train_loader = data.get_train_instance()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(DEVICE)\n",
    "            item = item.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(user, item)\n",
    "            \n",
    "            loss = criterion(prediction.view(-1).to(torch.float64), \n",
    "                            label.to(torch.float64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        hr_i, ndcg_i, mrr_i = metrics(model, test_loader, 10, DEVICE)\n",
    "        metrics_history['HR@10'].append(hr_i)\n",
    "        metrics_history['NDCG@10'].append(ndcg_i)\n",
    "\n",
    "        print(f\"[Epoch {epoch}]| Loss: {loss.item():.5f}\\n\"\\\n",
    "              f\"HR@10: {hr_i:.3f}\\tMRR@10: {mrr_i:.3f}\\tNDCG@10: {ndcg_i:.3f} |\")\n",
    "\n",
    "    return loss_history, metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMF(num_users=len(num_users), num_items=len(num_items), embedding_dim=32)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4c55708c594b2d82c7654f79c6e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.03803\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 1]| Loss: 0.00439\n",
      "HR@10: 0.333\tMRR@10: 0.048\tNDCG@10: 0.111 |\n",
      "[Epoch 2]| Loss: 0.00103\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 3]| Loss: 0.00050\n",
      "HR@10: 0.333\tMRR@10: 0.111\tNDCG@10: 0.167 |\n",
      "[Epoch 4]| Loss: 0.00035\n",
      "HR@10: 0.333\tMRR@10: 0.037\tNDCG@10: 0.100 |\n",
      "[Epoch 5]| Loss: 0.00016\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 6]| Loss: 0.00017\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 7]| Loss: 0.00011\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n",
      "[Epoch 8]| Loss: 0.00007\n",
      "HR@10: 0.333\tMRR@10: 0.033\tNDCG@10: 0.096 |\n",
      "[Epoch 9]| Loss: 0.00003\n",
      "HR@10: 0.000\tMRR@10: 0.000\tNDCG@10: 0.000 |\n"
     ]
    }
   ],
   "source": [
    "loss_history, metrics_history = train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim,\n",
    "                 layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embeddings_dim = embedding_dim\n",
    "        self.layers = layers\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=self.num_users,\n",
    "            embedding_dim=self.embeddings_dim\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=self.num_items,\n",
    "            embedding_dim=self.embeddings_dim\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.embeddings_dim * 2, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1], layers[2])\n",
    "        self.fc4 = nn.Linear(layers[2], layers[3])\n",
    "        self.fc5 = nn.Linear(layers[3], layers[4])\n",
    "        self.fc6 = nn.Linear(layers[4], layers[5])\n",
    "\n",
    "        self.affine_output = nn.Linear(self.layers[-1], 1)\n",
    "        self.activation_layer = nn.ReLU()\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_concat = torch.cat((user_embedding,\n",
    "                                    item_embedding), -1)\n",
    "        layer1 = self.activation_layer(self.fc1(element_concat))\n",
    "        layer2 = self.activation_layer(self.fc2(layer1))\n",
    "        layer3 = self.activation_layer(self.fc3(layer2))\n",
    "        layer4 = self.activation_layer(self.fc4(layer3))\n",
    "        layer5 = self.activation_layer(self.fc5(layer4))\n",
    "        layer6 = self.activation_layer(self.fc6(layer5))\n",
    "\n",
    "        logits = self.affine_output(layer6)\n",
    "        rating = self.activation(logits)\n",
    "\n",
    "        return rating\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(num_users=len(num_users),\n",
    "            num_items=len(num_items),\n",
    "            embedding_dim=128,\n",
    "            layers=[128, 64, 32, 16, 8, 4])\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 128, 128]            773,120\n",
      "├─Embedding: 1-2                         [-1, 128, 128]            474,368\n",
      "├─Linear: 1-3                            [-1, 128, 128]            32,896\n",
      "├─ReLU: 1-4                              [-1, 128, 128]            --\n",
      "├─Linear: 1-5                            [-1, 128, 64]             8,256\n",
      "├─ReLU: 1-6                              [-1, 128, 64]             --\n",
      "├─Linear: 1-7                            [-1, 128, 32]             2,080\n",
      "├─ReLU: 1-8                              [-1, 128, 32]             --\n",
      "├─Linear: 1-9                            [-1, 128, 16]             528\n",
      "├─ReLU: 1-10                             [-1, 128, 16]             --\n",
      "├─Linear: 1-11                           [-1, 128, 8]              136\n",
      "├─ReLU: 1-12                             [-1, 128, 8]              --\n",
      "├─Linear: 1-13                           [-1, 128, 4]              36\n",
      "├─ReLU: 1-14                             [-1, 128, 4]              --\n",
      "├─Linear: 1-15                           [-1, 128, 1]              5\n",
      "├─Sigmoid: 1-16                          [-1, 128, 1]              --\n",
      "==========================================================================================\n",
      "Total params: 1,291,425\n",
      "Trainable params: 1,291,425\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.29\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.50\n",
      "Params size (MB): 4.93\n",
      "Estimated Total Size (MB): 5.42\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 128, 128]            773,120\n",
       "├─Embedding: 1-2                         [-1, 128, 128]            474,368\n",
       "├─Linear: 1-3                            [-1, 128, 128]            32,896\n",
       "├─ReLU: 1-4                              [-1, 128, 128]            --\n",
       "├─Linear: 1-5                            [-1, 128, 64]             8,256\n",
       "├─ReLU: 1-6                              [-1, 128, 64]             --\n",
       "├─Linear: 1-7                            [-1, 128, 32]             2,080\n",
       "├─ReLU: 1-8                              [-1, 128, 32]             --\n",
       "├─Linear: 1-9                            [-1, 128, 16]             528\n",
       "├─ReLU: 1-10                             [-1, 128, 16]             --\n",
       "├─Linear: 1-11                           [-1, 128, 8]              136\n",
       "├─ReLU: 1-12                             [-1, 128, 8]              --\n",
       "├─Linear: 1-13                           [-1, 128, 4]              36\n",
       "├─ReLU: 1-14                             [-1, 128, 4]              --\n",
       "├─Linear: 1-15                           [-1, 128, 1]              5\n",
       "├─Sigmoid: 1-16                          [-1, 128, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 1,291,425\n",
       "Trainable params: 1,291,425\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.29\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.50\n",
       "Params size (MB): 4.93\n",
       "Estimated Total Size (MB): 5.42\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [(128,), (128,)], dtypes=[torch.long, torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85a68c958142aebd95342769056d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.00001\n",
      "HR@10: 0.333\tMRR@10: 0.167\tNDCG@10: 0.210 |\n",
      "[Epoch 1]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.667\tNDCG@10: 0.667 |\n",
      "[Epoch 2]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.114\tNDCG@10: 0.240 |\n",
      "[Epoch 3]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.167\tNDCG@10: 0.285 |\n",
      "[Epoch 4]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.144\tNDCG@10: 0.263 |\n",
      "[Epoch 5]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.200\tNDCG@10: 0.383 |\n",
      "[Epoch 6]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.089\tNDCG@10: 0.216 |\n",
      "[Epoch 7]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.079\tNDCG@10: 0.205 |\n",
      "[Epoch 8]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.089\tNDCG@10: 0.216 |\n",
      "[Epoch 9]| Loss: 0.00000\n",
      "HR@10: 0.667\tMRR@10: 0.103\tNDCG@10: 0.230 |\n"
     ]
    }
   ],
   "source": [
    "loss_history_mlp, metrics_history_mlp =\\\n",
    "    train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim,\n",
    "                 layers):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.layers = layers\n",
    "\n",
    "        self.embedding_user_mlp = nn.Embedding(\n",
    "            num_embeddings=self.num_users + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.embedding_item_mlp = nn.Embedding(\n",
    "            num_embeddings=self.num_items + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "\n",
    "        self.embedding_user_mf = nn.Embedding(\n",
    "            num_embeddings=self.num_users + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.embedding_item_mf = nn.Embedding(\n",
    "            num_embeddings=self.num_items + 1,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim * 2, self.layers[0]),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[0], self.layers[1]),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[1], self.layers[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.layers[2], self.layers[3])\n",
    "        )\n",
    "\n",
    "        self.affine_output = nn.Linear(\n",
    "            self.layers[-1] + self.embedding_dim, 1\n",
    "        )\n",
    "        self.activate = nn.Sigmoid()\n",
    "        \n",
    "        # nn.init.xavier_uniform_(self.embedding_user_mlp.weight)\n",
    "        # nn.init.xavier_uniform_(self.embedding_item_mlp.weight)\n",
    "\n",
    "        # nn.init.xavier_uniform_(self.embedding_user_mf.weight)\n",
    "        # nn.init.xavier_uniform_(self.embedding_item_mf.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n",
    "\n",
    "        user_embedding_mf = self.embedding_user_mf(user_indices)\n",
    "        item_embedding_mf = self.embedding_item_mf(item_indices)\n",
    "\n",
    "        element_product_mf = torch.mul(\n",
    "            user_embedding_mf,\n",
    "            item_embedding_mf\n",
    "        )\n",
    "\n",
    "        element_product_mlp = torch.cat(\n",
    "            (user_embedding_mlp, item_embedding_mlp), -1\n",
    "        )\n",
    "\n",
    "        layers = self.fc(element_product_mlp)\n",
    "\n",
    "        logits = self.affine_output(torch.cat(\n",
    "            (layers, element_product_mf), -1)\n",
    "        )\n",
    "        rating = self.activate(logits)\n",
    "\n",
    "        return rating\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(num_users=len(num_users),\n",
    "              num_items=len(num_items),\n",
    "              embedding_dim=128,\n",
    "              layers=[32, 16, 8, 4])\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 128, 128]            773,248\n",
      "├─Embedding: 1-2                         [-1, 128, 128]            474,496\n",
      "├─Embedding: 1-3                         [-1, 128, 128]            773,248\n",
      "├─Embedding: 1-4                         [-1, 128, 128]            474,496\n",
      "├─Sequential: 1-5                        [-1, 128, 4]              --\n",
      "|    └─Linear: 2-1                       [-1, 128, 32]             8,224\n",
      "|    └─Dropout: 2-2                      [-1, 128, 32]             --\n",
      "|    └─ReLU: 2-3                         [-1, 128, 32]             --\n",
      "|    └─Linear: 2-4                       [-1, 128, 16]             528\n",
      "|    └─Dropout: 2-5                      [-1, 128, 16]             --\n",
      "|    └─ReLU: 2-6                         [-1, 128, 16]             --\n",
      "|    └─Linear: 2-7                       [-1, 128, 8]              136\n",
      "|    └─ReLU: 2-8                         [-1, 128, 8]              --\n",
      "|    └─Linear: 2-9                       [-1, 128, 4]              36\n",
      "├─Linear: 1-6                            [-1, 128, 1]              133\n",
      "├─Sigmoid: 1-7                           [-1, 128, 1]              --\n",
      "==========================================================================================\n",
      "Total params: 2,504,545\n",
      "Trainable params: 2,504,545\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.56\n",
      "Params size (MB): 9.55\n",
      "Estimated Total Size (MB): 10.11\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 128, 128]            773,248\n",
       "├─Embedding: 1-2                         [-1, 128, 128]            474,496\n",
       "├─Embedding: 1-3                         [-1, 128, 128]            773,248\n",
       "├─Embedding: 1-4                         [-1, 128, 128]            474,496\n",
       "├─Sequential: 1-5                        [-1, 128, 4]              --\n",
       "|    └─Linear: 2-1                       [-1, 128, 32]             8,224\n",
       "|    └─Dropout: 2-2                      [-1, 128, 32]             --\n",
       "|    └─ReLU: 2-3                         [-1, 128, 32]             --\n",
       "|    └─Linear: 2-4                       [-1, 128, 16]             528\n",
       "|    └─Dropout: 2-5                      [-1, 128, 16]             --\n",
       "|    └─ReLU: 2-6                         [-1, 128, 16]             --\n",
       "|    └─Linear: 2-7                       [-1, 128, 8]              136\n",
       "|    └─ReLU: 2-8                         [-1, 128, 8]              --\n",
       "|    └─Linear: 2-9                       [-1, 128, 4]              36\n",
       "├─Linear: 1-6                            [-1, 128, 1]              133\n",
       "├─Sigmoid: 1-7                           [-1, 128, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 2,504,545\n",
       "Trainable params: 2,504,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.51\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.56\n",
       "Params size (MB): 9.55\n",
       "Estimated Total Size (MB): 10.11\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [(128,), (128,)], dtypes=[torch.long, torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3108917d8ddb413e89c13c346d504037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]| Loss: 0.00017\n",
      "HR@10: 0.333\tMRR@10: 0.056\tNDCG@10: 0.119 |\n",
      "[Epoch 1]| Loss: 0.00005\n",
      "HR@10: 0.667\tMRR@10: 0.095\tNDCG@10: 0.222 |\n",
      "[Epoch 2]| Loss: 0.00001\n",
      "HR@10: 1.000\tMRR@10: 0.145\tNDCG@10: 0.334 |\n",
      "[Epoch 3]| Loss: 0.00001\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 4]| Loss: 0.00002\n",
      "HR@10: 1.000\tMRR@10: 0.194\tNDCG@10: 0.377 |\n",
      "[Epoch 5]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.131\tNDCG@10: 0.321 |\n",
      "[Epoch 6]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.120\tNDCG@10: 0.311 |\n",
      "[Epoch 7]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 8]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n",
      "[Epoch 9]| Loss: 0.00000\n",
      "HR@10: 1.000\tMRR@10: 0.125\tNDCG@10: 0.315 |\n"
     ]
    }
   ],
   "source": [
    "loss_history_neumf, metrics_history_neumf =\\\n",
    "    train_pipeline(model, optimizer, criterion, data, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
