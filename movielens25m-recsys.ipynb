{"cells":[{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:48.177771Z","iopub.status.busy":"2023-05-14T22:15:48.177370Z","iopub.status.idle":"2023-05-14T22:15:51.495548Z","shell.execute_reply":"2023-05-14T22:15:51.494592Z","shell.execute_reply.started":"2023-05-14T22:15:48.177741Z"},"trusted":true},"outputs":[],"source":["import time\n","from tqdm.notebook import trange, tqdm\n","import random\n","import zipfile\n","import os\n","import warnings\n","\n","import numpy as np\n","# import pandas as pd\n","import modin.pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","# from torchsummary import summary\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:51.497945Z","iopub.status.busy":"2023-05-14T22:15:51.497331Z","iopub.status.idle":"2023-05-14T22:15:51.531532Z","shell.execute_reply":"2023-05-14T22:15:51.530539Z","shell.execute_reply.started":"2023-05-14T22:15:51.497910Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["ZIP_FILE = 'ml-10m.zip'\n","DATA_URL = 'https://files.grouplens.org/datasets/movielens/'\\\n","            '{}'.format(ZIP_FILE)\n","DATA_PATH = '/kaggle/input/movielens-1m-dataset/ratings.dat'\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if not os.path.exists(DATA_PATH):\n","    wget.download(DATA_URL)\n","    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n","        zip_ref.extractall('./')\n","else:\n","    pass"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["подготовка формата для pytorch"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:55.770292Z","iopub.status.busy":"2023-05-14T22:15:55.769702Z","iopub.status.idle":"2023-05-14T22:15:55.779836Z","shell.execute_reply":"2023-05-14T22:15:55.778771Z","shell.execute_reply.started":"2023-05-14T22:15:55.770257Z"},"trusted":true},"outputs":[],"source":["class UserItemRatingDataset(Dataset):\n","    def __init__(self, user:list, item:list, rating:list):\n","        super(UserItemRatingDataset, self).__init__()\n","        \n","        self.user = torch.tensor(user, dtype=torch.long)\n","        self.item = torch.tensor(item, dtype=torch.long)\n","        self.target = torch.tensor(rating, dtype=torch.float)\n","\n","    def __len__(self):\n","        return len(self.target)\n","        \n","    def __getitem__(self, idx):\n","        return self.user[idx], self.item[idx], self.target[idx]\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:56.134723Z","iopub.status.busy":"2023-05-14T22:15:56.134359Z","iopub.status.idle":"2023-05-14T22:15:56.161637Z","shell.execute_reply":"2023-05-14T22:15:56.160645Z","shell.execute_reply.started":"2023-05-14T22:15:56.134693Z"},"trusted":true},"outputs":[],"source":["class NCFData(object):\n","    def __init__(self, ratings, num_negatives, num_negatives_test, batch_size: int):\n","        self.ratings = ratings\n","        self.num_negatives = num_negatives\n","        self.num_negatives_test = num_negatives_test\n","        self.batch_size = batch_size\n","\n","        self.preprocess_ratings = self._reindex(self.ratings)\n","        self.user_pool = set(self.ratings[\"user_id\"].unique())\n","        self.item_pool = set(self.ratings[\"item_id\"].unique())\n","\n","        self.train_ratings, self.test_ratings = self._leave_p_out(\n","            self.preprocess_ratings\n","        )\n","        self.negatives = self._negative_sampling(self.preprocess_ratings)\n","\n","    def _reindex(self, ratings):\n","        user = list(ratings[\"user_id\"].drop_duplicates())\n","        self.user2id = {w: i for i, w in enumerate(user)}\n","\n","        item = list(ratings[\"item_id\"].drop_duplicates())\n","        self.item2id = {w: i for i, w in enumerate(item)}\n","\n","        ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: self.user2id[x])\n","        ratings[\"item_id\"] = ratings[\"item_id\"].apply(lambda x: self.item2id[x])\n","        ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x > 0))\n","\n","        return ratings\n","\n","    def _leave_one_out(self, ratings):\n","        ratings[\"rank_latest\"] = ratings.groupby([\"user_id\"])[\"timestamp\"].rank(\n","            method=\"first\", ascending=False\n","        )\n","        test = ratings.loc[ratings[\"rank_latest\"] == 1]\n","        train = ratings.loc[ratings[\"rank_latest\"] > 1]\n","        \n","        return train[[\"user_id\", \"item_id\", \"rating\"]], test[[\"user_id\", \"item_id\", \"rating\"]]\n","    \n","    def _leave_p_out(self, ratings, p=10):\n","        ratings[\"rank_latest\"] = ratings.groupby([\"user_id\"])[\"timestamp\"].rank(\n","            method=\"first\", ascending=False\n","        )\n","        test = ratings.loc[ratings[\"rank_latest\"] < p+1]\n","        train = ratings.loc[ratings[\"rank_latest\"] > p]\n","        return train[[\"user_id\", \"item_id\", \"rating\"]], test[[\"user_id\", \"item_id\", \"rating\"]]\n","\n","    def _negative_sampling(self, ratings):\n","        interact_status = (\n","            ratings.groupby('user_id')['item_id']\n","            .apply(set)\n","            .reset_index()\n","            .rename(columns={'item_id': 'interacted_items'})\n","        )\n","\n","        interact_status[\"negative_samples\"] = [\n","            random.sample(\n","                self.item_pool - interact_status[\"interacted_items\"].iloc[i],\n","                self.num_negatives_test,\n","            )\n","            for i in range(interact_status[\"interacted_items\"].shape[0])\n","        ]\n","\n","        return interact_status[['user_id', 'negative_samples', 'interacted_items']]\n","\n","    def get_train_instance(self):\n","        users, items, ratings = [], [], []        \n","        train_ratings_negatives = pd.DataFrame()\n","        train_ratings_negatives['user_id'] = self.negatives['user_id']\n","        train_ratings_negatives[\"negatives\"] = [\n","            random.sample(\n","                self.item_pool - self.negatives['interacted_items'].iloc[i],\n","                len(self.negatives['interacted_items'].iloc[i]) if len(self.item_pool) - 2 * len(self.negatives['interacted_items'].iloc[i]) > 0 else self.num_negatives,\n","            )\n","            for i in range(self.negatives['interacted_items'].shape[0])\n","        ]\n","        train_ratings_negatives = train_ratings_negatives.explode(\"negatives\")\n","\n","        users = np.append(self.train_ratings[\"user_id\"], \n","                          train_ratings_negatives[\"user_id\"]).astype(np.int64)\n","        items = np.append(self.train_ratings[\"item_id\"], \n","                          train_ratings_negatives[\"negatives\"]).astype(np.int64)\n","        ratings = np.append(self.train_ratings[\"rating\"], \n","                            [0 for i in range(train_ratings_negatives.shape[0])]).astype(np.int64)\n","        \n","        assert len(users) == len(items) and len(items) == len(ratings)\n","\n","        dataset = UserItemRatingDataset(user=users, item=items, rating=ratings)\n","        return DataLoader(\n","            dataset, batch_size=self.batch_size, shuffle=True, num_workers=4\n","        )\n","\n","    def get_test_instance(self, p=10):\n","        users, items, ratings = [], [], []\n","        test_ratings = pd.merge(\n","            self.test_ratings,\n","            self.negatives[[\"user_id\", \"negative_samples\"]],\n","            on=\"user_id\",\n","        )\n","        \n","        for user in tqdm(np.unique(test_ratings['user_id'])):\n","            for row in (test_ratings.loc[test_ratings['user_id'] == user]).itertuples():\n","                users.append(int(row.user_id))\n","                items.append(int(row.item_id))\n","                ratings.append(float(row.rating))\n","            for item_negative in test_ratings.loc[test_ratings['user_id'] == user]['negative_samples'].iloc[0]:\n","                users.append(int(user))\n","                items.append(int(item_negative))\n","                ratings.append(float(0))\n","\n","        dataset = UserItemRatingDataset(user=users, item=items, rating=ratings)\n","        return DataLoader(\n","            dataset, batch_size=self.num_negatives_test+p, shuffle=False, num_workers=4\n","        )"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:56.701165Z","iopub.status.busy":"2023-05-14T22:15:56.700800Z","iopub.status.idle":"2023-05-14T22:15:56.706983Z","shell.execute_reply":"2023-05-14T22:15:56.706067Z","shell.execute_reply.started":"2023-05-14T22:15:56.701135Z"},"trusted":true},"outputs":[],"source":["def data2excel(name_excel:str, loss:list, metrics:dict):\n","    df = pd.DataFrame({\n","        \"eposh\": [i for i in range(1, len(loss)+1)],\n","        \"loss\": loss,\n","        \"test_loss\": metrics[\"Test_loss\"],\n","        \"HR@10\": metrics[\"HR@10\"],\n","        \"Precision@10\": metrics[\"Precision@10\"],\n","        \"Recall@10\": metrics[\"Recall@10\"],\n","        \"MAP@10\": metrics[\"MAP@10\"],\n","        \"NDCG@10\": metrics[\"NDCG@10\"],\n","        \"MRR@10\": metrics[\"MRR@10\"],\n","        \n","    })\n","    \n","    df.to_excel(f\"{name_excel}.xlsx\")\n","    \n","    return df"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:15:57.581258Z","iopub.status.busy":"2023-05-14T22:15:57.580566Z","iopub.status.idle":"2023-05-14T22:15:59.070230Z","shell.execute_reply":"2023-05-14T22:15:59.069227Z","shell.execute_reply.started":"2023-05-14T22:15:57.581225Z"},"trusted":true},"outputs":[],"source":["# ml_1m = pd.read_csv(DATA_PATH, sep='::', engine='python',\n","#                     names=['user_id', 'item_id', 'rating', 'timestamp'])\n","ml_10m = pd.read_parquet('./ratings_10m.parquet')"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>122</td>\n","      <td>5.0</td>\n","      <td>838985046</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>185</td>\n","      <td>5.0</td>\n","      <td>838983525</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>231</td>\n","      <td>5.0</td>\n","      <td>838983392</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>292</td>\n","      <td>5.0</td>\n","      <td>838983421</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>316</td>\n","      <td>5.0</td>\n","      <td>838983392</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  item_id  rating  timestamp\n","0        1      122     5.0  838985046\n","1        1      185     5.0  838983525\n","2        1      231     5.0  838983392\n","3        1      292     5.0  838983421\n","4        1      316     5.0  838983392"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["ml_10m.head()"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:00.057836Z","iopub.status.busy":"2023-05-14T22:16:00.056957Z","iopub.status.idle":"2023-05-14T22:16:00.399481Z","shell.execute_reply":"2023-05-14T22:16:00.398542Z","shell.execute_reply.started":"2023-05-14T22:16:00.057796Z"},"trusted":true},"outputs":[{"data":{"text/plain":["item_id    143.10733\n","dtype: float64"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["ml_10m[[\"user_id\", \"item_id\"]].groupby(['user_id']).agg('count').mean()"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:01.558239Z","iopub.status.busy":"2023-05-14T22:16:01.557835Z","iopub.status.idle":"2023-05-14T22:16:01.645497Z","shell.execute_reply":"2023-05-14T22:16:01.644603Z","shell.execute_reply.started":"2023-05-14T22:16:01.558206Z"},"trusted":true},"outputs":[],"source":["num_users = ml_10m['user_id'].nunique()\n","num_items = ml_10m['item_id'].nunique()"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:02.334108Z","iopub.status.busy":"2023-05-14T22:16:02.333723Z","iopub.status.idle":"2023-05-14T22:16:54.621045Z","shell.execute_reply":"2023-05-14T22:16:54.620071Z","shell.execute_reply.started":"2023-05-14T22:16:02.334077Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-23 19:04:00,854 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:33601 (pid=20940) exceeded 95% memory budget. Restarting...\n","2023-05-23 19:04:00,905 - distributed.scheduler - WARNING - Worker tcp://127.0.0.1:38527 failed to acquire keys: {'function-1975def6dd81424a93b0692bb29e84e1': ('tcp://127.0.0.1:33601',)}\n","2023-05-23 19:04:00,907 - distributed.scheduler - WARNING - Worker tcp://127.0.0.1:43243 failed to acquire keys: {'function-1975def6dd81424a93b0692bb29e84e1': ('tcp://127.0.0.1:33601',)}\n","2023-05-23 19:04:00,901 - distributed.worker - WARNING - Could not find data: {'function-1975def6dd81424a93b0692bb29e84e1': ['tcp://127.0.0.1:33601']} on workers: ['tcp://127.0.0.1:33601'] (who_has: {'function-1975def6dd81424a93b0692bb29e84e1': ['tcp://127.0.0.1:33601']})\n","2023-05-23 19:04:00,902 - distributed.worker - WARNING - Could not find data: {'function-1975def6dd81424a93b0692bb29e84e1': ['tcp://127.0.0.1:33601']} on workers: ['tcp://127.0.0.1:33601'] (who_has: {'function-1975def6dd81424a93b0692bb29e84e1': ['tcp://127.0.0.1:33601']})\n","2023-05-23 19:04:00,935 - distributed.nanny - WARNING - Restarting worker\n","2023-05-23 19:04:01,570 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:38799 (pid=20945) exceeded 95% memory budget. Restarting...\n","2023-05-23 19:04:01,631 - distributed.scheduler - WARNING - Communication with worker tcp://127.0.0.1:38799 failed during replication: CommClosedError: in <TCP (closed) ConnectionPool.gather local=tcp://127.0.0.1:41788 remote=tcp://127.0.0.1:38799>: ConnectionResetError: [Errno 104] Connection reset by peer\n","2023-05-23 19:04:01,636 - distributed.core - ERROR - Exception while handling op scatter\n","Traceback (most recent call last):\n","  File \"/home/laptopml/anaconda3/lib/python3.10/site-packages/distributed/core.py\", line 769, in _handle_comm\n","    result = await result\n","  File \"/home/laptopml/anaconda3/lib/python3.10/site-packages/distributed/scheduler.py\", line 5023, in scatter\n","    await self.replicate(keys=keys, workers=workers, n=n)\n","  File \"/home/laptopml/anaconda3/lib/python3.10/site-packages/distributed/scheduler.py\", line 5781, in replicate\n","    for ws in random.sample(tuple(workers - ts.who_has), count):\n","  File \"/home/laptopml/anaconda3/lib/python3.10/random.py\", line 482, in sample\n","    raise ValueError(\"Sample larger than population or is negative\")\n","ValueError: Sample larger than population or is negative\n","2023-05-23 19:04:01,652 - distributed.nanny - WARNING - Restarting worker\n","2023-05-23 19:04:02,720 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:38527 (pid=20936) exceeded 95% memory budget. Restarting...\n","2023-05-23 19:04:02,787 - distributed.nanny - WARNING - Restarting worker\n","2023-05-23 19:04:03,276 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:36245 (pid=20949) exceeded 95% memory budget. Restarting...\n","2023-05-23 19:04:03,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76v9nk42', purging\n","2023-05-23 19:04:03,356 - distributed.nanny - WARNING - Restarting worker\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe802e0fd00>\n","Traceback (most recent call last):\n","  File \"/home/laptopml/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/home/laptopml/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/home/laptopml/anaconda3/lib/python3.10/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","  File \"/home/laptopml/anaconda3/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/home/laptopml/anaconda3/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n","    ready = selector.select(timeout)\n","  File \"/home/laptopml/anaconda3/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n"]},{"ename":"ValueError","evalue":"Sample larger than population or is negative","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m NCFData(ml_10m, num_negatives\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m            num_negatives_test\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m)\n","Cell \u001b[0;32mIn[62], line 8\u001b[0m, in \u001b[0;36mNCFData.__init__\u001b[0;34m(self, ratings, num_negatives, num_negatives_test, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_negatives_test \u001b[39m=\u001b[39m num_negatives_test\n\u001b[1;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m batch_size\n\u001b[0;32m----> 8\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_ratings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mratings)\n\u001b[1;32m      9\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_pool \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratings[\u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[1;32m     10\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_pool \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratings[\u001b[39m\"\u001b[39m\u001b[39mitem_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique())\n","Cell \u001b[0;32mIn[62], line 25\u001b[0m, in \u001b[0;36mNCFData._reindex\u001b[0;34m(self, ratings)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem2id \u001b[39m=\u001b[39m {w: i \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(item)}\n\u001b[1;32m     24\u001b[0m ratings[\u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ratings[\u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser2id[x])\n\u001b[0;32m---> 25\u001b[0m ratings[\u001b[39m\"\u001b[39m\u001b[39mitem_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ratings[\u001b[39m\"\u001b[39;49m\u001b[39mitem_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem2id[x])\n\u001b[1;32m     26\u001b[0m ratings[\u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ratings[\u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mfloat\u001b[39m(x \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m ratings\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/pandas/series.py:704\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m             result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_compiler\u001b[39m.\u001b[39mapply_on_series(f)\n\u001b[1;32m    703\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m             result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap(f)\u001b[39m.\u001b[39m_query_compiler\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m return_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    707\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataframe\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/pandas/series.py:1296\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39marg\u001b[39m(s):\n\u001b[1;32m   1293\u001b[0m         \u001b[39mreturn\u001b[39;00m mapper\u001b[39m.\u001b[39mget(s, np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m   1295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__constructor__(\n\u001b[0;32m-> 1296\u001b[0m     query_compiler\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_compiler\u001b[39m.\u001b[39;49mapplymap(\n\u001b[1;32m   1297\u001b[0m         \u001b[39mlambda\u001b[39;49;00m s: arg(s)\n\u001b[1;32m   1298\u001b[0m         \u001b[39mif\u001b[39;49;00m pandas\u001b[39m.\u001b[39;49misnull(s) \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mTrue\u001b[39;49;00m \u001b[39mor\u001b[39;49;00m na_action \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1299\u001b[0m         \u001b[39melse\u001b[39;49;00m s\n\u001b[1;32m   1300\u001b[0m     )\n\u001b[1;32m   1301\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/algebra/map.py:50\u001b[0m, in \u001b[0;36mMap.register.<locals>.caller\u001b[0;34m(query_compiler, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m\"\"\"Execute Map function against passed query compiler.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m shape_hint \u001b[39m=\u001b[39m call_kwds\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mshape_hint\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m kwargs\u001b[39m.\u001b[39mpop(\n\u001b[1;32m     47\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshape_hint\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m query_compiler\u001b[39m.\u001b[39m__constructor__(\n\u001b[0;32m---> 50\u001b[0m     query_compiler\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m     51\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: function(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39;49mcall_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcall_kwds\n\u001b[1;32m     52\u001b[0m     ),\n\u001b[1;32m     53\u001b[0m     shape_hint\u001b[39m=\u001b[39mshape_hint,\n\u001b[1;32m     54\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/utils.py:375\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[39melif\u001b[39;00m apply_axis \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    374\u001b[0m         obj\u001b[39m.\u001b[39m_propagate_index_objs(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m apply_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m transpose:\n\u001b[1;32m    377\u001b[0m     result\u001b[39m.\u001b[39m_deferred_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deferred_index\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:1840\u001b[0m, in \u001b[0;36mPandasDataframe.map\u001b[0;34m(self, func, dtypes)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[39m@lazy_metadata_decorator\u001b[39m(apply_axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func: Callable, dtypes: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPandasDataframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m \u001b[39m    Perform a function that maps across the entire dataset.\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[39m        A new dataframe.\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1840\u001b[0m     new_partitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partition_mgr_cls\u001b[39m.\u001b[39;49mmap_partitions(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partitions, func)\n\u001b[1;32m   1841\u001b[0m     \u001b[39mif\u001b[39;00m dtypes \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcopy\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1842\u001b[0m         dtypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_dtypes_cache()\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:58\u001b[0m, in \u001b[0;36mwait_computations_if_benchmark_mode.<locals>.wait\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     57\u001b[0m     \u001b[39m\"\"\"Wait for computation results.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mcls\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m BenchmarkMode\u001b[39m.\u001b[39mget():\n\u001b[1;32m     60\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtuple\u001b[39m):\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:516\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.map_partitions\u001b[0;34m(cls, partitions, map_func)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    499\u001b[0m \u001b[39m@wait_computations_if_benchmark_mode\u001b[39m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_partitions\u001b[39m(\u001b[39mcls\u001b[39m, partitions, map_func):\n\u001b[1;32m    501\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m    Apply `map_func` to every partition in `partitions`.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39m        An array of partitions\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     preprocessed_map_func \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess_func(map_func)\n\u001b[1;32m    517\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\n\u001b[1;32m    518\u001b[0m         [\n\u001b[1;32m    519\u001b[0m             [part\u001b[39m.\u001b[39mapply(preprocessed_map_func) \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m row_of_parts]\n\u001b[1;32m    520\u001b[0m             \u001b[39mfor\u001b[39;00m row_of_parts \u001b[39min\u001b[39;00m partitions\n\u001b[1;32m    521\u001b[0m         ]\n\u001b[1;32m    522\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:120\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.preprocess_func\u001b[0;34m(cls, map_func)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_func\u001b[39m(\u001b[39mcls\u001b[39m, map_func):\n\u001b[1;32m     95\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    Preprocess a function to be applied to `PandasDataframePartition` objects.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39m    you are using does not require any modification to a given function.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_partition_class\u001b[39m.\u001b[39;49mpreprocess_func(map_func)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/execution/dask/implementations/pandas_on_dask/partitioning/partition.py:246\u001b[0m, in \u001b[0;36mPandasOnDaskDataframePartition.preprocess_func\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_func\u001b[39m(\u001b[39mcls\u001b[39m, func):\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m    Preprocess a function before an ``apply`` call.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39m        An object that can be accepted by ``apply``.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m DaskWrapper\u001b[39m.\u001b[39;49mput(func, \u001b[39mhash\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/modin/core/execution/dask/common/engine_wrapper.py:135\u001b[0m, in \u001b[0;36mDaskWrapper.put\u001b[0;34m(cls, data, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     data \u001b[39m=\u001b[39m UserDict(data)\n\u001b[1;32m    134\u001b[0m client \u001b[39m=\u001b[39m default_client()\n\u001b[0;32m--> 135\u001b[0m \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mscatter(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/client.py:2384\u001b[0m, in \u001b[0;36mClient.scatter\u001b[0;34m(self, data, workers, broadcast, direct, hash, timeout, asynchronous)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2383\u001b[0m     local_worker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msync(\n\u001b[1;32m   2385\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scatter,\n\u001b[1;32m   2386\u001b[0m     data,\n\u001b[1;32m   2387\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2388\u001b[0m     broadcast\u001b[39m=\u001b[39;49mbroadcast,\n\u001b[1;32m   2389\u001b[0m     direct\u001b[39m=\u001b[39;49mdirect,\n\u001b[1;32m   2390\u001b[0m     local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   2391\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   2392\u001b[0m     asynchronous\u001b[39m=\u001b[39;49masynchronous,\n\u001b[1;32m   2393\u001b[0m     \u001b[39mhash\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mhash\u001b[39;49m,\n\u001b[1;32m   2394\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/utils.py:338\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m future\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    339\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, callback_timeout\u001b[39m=\u001b[39;49mcallback_timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    340\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/utils.py:405\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[1;32m    404\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error\n\u001b[0;32m--> 405\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    406\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/utils.py:378\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m         future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[1;32m    377\u001b[0m     future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 378\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m future\n\u001b[1;32m    379\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     error \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    763\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/client.py:2269\u001b[0m, in \u001b[0;36mClient._scatter\u001b[0;34m(self, data, workers, broadcast, direct, local_worker, timeout, hash)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mupdate_data(\n\u001b[1;32m   2266\u001b[0m             who_has\u001b[39m=\u001b[39mwho_has, nbytes\u001b[39m=\u001b[39mnbytes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\n\u001b[1;32m   2267\u001b[0m         )\n\u001b[1;32m   2268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2269\u001b[0m         \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mscatter(\n\u001b[1;32m   2270\u001b[0m             data\u001b[39m=\u001b[39mdata2,\n\u001b[1;32m   2271\u001b[0m             workers\u001b[39m=\u001b[39mworkers,\n\u001b[1;32m   2272\u001b[0m             client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid,\n\u001b[1;32m   2273\u001b[0m             broadcast\u001b[39m=\u001b[39mbroadcast,\n\u001b[1;32m   2274\u001b[0m             timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   2275\u001b[0m         )\n\u001b[1;32m   2277\u001b[0m out \u001b[39m=\u001b[39m {k: Future(k, \u001b[39mself\u001b[39m, inform\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m data}\n\u001b[1;32m   2278\u001b[0m \u001b[39mfor\u001b[39;00m key, typ \u001b[39min\u001b[39;00m types\u001b[39m.\u001b[39mitems():\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/core.py:1153\u001b[0m, in \u001b[0;36mPooledRPCCall.__getattr__.<locals>.send_recv_from_rpc\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m prev_name, comm\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m comm\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39mConnectionPool.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m key\n\u001b[1;32m   1152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m send_recv(comm\u001b[39m=\u001b[39mcomm, op\u001b[39m=\u001b[39mkey, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mreuse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddr, comm)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/core.py:943\u001b[0m, in \u001b[0;36msend_recv\u001b[0;34m(comm, reply, serializers, deserializers, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     _, exc, tb \u001b[39m=\u001b[39m clean_exception(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse)\n\u001b[1;32m    942\u001b[0m     \u001b[39massert\u001b[39;00m exc\n\u001b[0;32m--> 943\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    944\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(response[\u001b[39m\"\u001b[39m\u001b[39mexception_text\u001b[39m\u001b[39m\"\u001b[39m])\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/core.py:769\u001b[0m, in \u001b[0;36m_handle_comm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    767\u001b[0m     result \u001b[39m=\u001b[39m handler(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39miscoroutine(result):\n\u001b[0;32m--> 769\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m result\n\u001b[1;32m    770\u001b[0m \u001b[39melif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[1;32m    771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    772\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComm handler returned unknown awaitable. Expected coroutine, instead got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(result)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/scheduler.py:5023\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5021\u001b[0m \u001b[39mif\u001b[39;00m broadcast:\n\u001b[1;32m   5022\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(nthreads) \u001b[39mif\u001b[39;00m broadcast \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m broadcast\n\u001b[0;32m-> 5023\u001b[0m     \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(keys\u001b[39m=\u001b[39mkeys, workers\u001b[39m=\u001b[39mworkers, n\u001b[39m=\u001b[39mn)\n\u001b[1;32m   5025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_event(\n\u001b[1;32m   5026\u001b[0m     [client, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m], {\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mscatter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m: client, \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(data)}\n\u001b[1;32m   5027\u001b[0m )\n\u001b[1;32m   5028\u001b[0m \u001b[39mreturn\u001b[39;00m keys\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/distributed/scheduler.py:5781\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5778\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_missing, branching_factor \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(ts\u001b[39m.\u001b[39mwho_has))\n\u001b[1;32m   5779\u001b[0m     \u001b[39massert\u001b[39;00m count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 5781\u001b[0m     \u001b[39mfor\u001b[39;00m ws \u001b[39min\u001b[39;00m random\u001b[39m.\u001b[39msample(\u001b[39mtuple\u001b[39m(workers \u001b[39m-\u001b[39m ts\u001b[39m.\u001b[39mwho_has), count):\n\u001b[1;32m   5782\u001b[0m         gathers[ws\u001b[39m.\u001b[39maddress][ts\u001b[39m.\u001b[39mkey] \u001b[39m=\u001b[39m [\n\u001b[1;32m   5783\u001b[0m             wws\u001b[39m.\u001b[39maddress \u001b[39mfor\u001b[39;00m wws \u001b[39min\u001b[39;00m ts\u001b[39m.\u001b[39mwho_has\n\u001b[1;32m   5784\u001b[0m         ]\n\u001b[1;32m   5786\u001b[0m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\n\u001b[1;32m   5787\u001b[0m     \u001b[39m*\u001b[39m(\n\u001b[1;32m   5788\u001b[0m         \u001b[39m# Note: this never raises exceptions\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5791\u001b[0m     )\n\u001b[1;32m   5792\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.10/random.py:482\u001b[0m, in \u001b[0;36msample\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m randbelow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m k \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n:\n\u001b[0;32m--> 482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample larger than population or is negative\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m result \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m k\n\u001b[1;32m    484\u001b[0m setsize \u001b[39m=\u001b[39m \u001b[39m21\u001b[39m        \u001b[39m# size of a small set minus size of an empty list\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"]}],"source":["data = NCFData(ml_10m, num_negatives=4,\n","           num_negatives_test=100, batch_size=2048)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:54.623427Z","iopub.status.busy":"2023-05-14T22:16:54.623085Z","iopub.status.idle":"2023-05-14T22:16:54.642479Z","shell.execute_reply":"2023-05-14T22:16:54.641508Z","shell.execute_reply.started":"2023-05-14T22:16:54.623396Z"},"trusted":true},"outputs":[],"source":["def hit(y_pred, y_true):\n","    hr = set(y_pred).intersection({y_true})\n","    if len(hr) != 0:\n","        return 1\n","    return 0\n","\n","def precision(y_pred, y_true, p=10):\n","    return len((set(y_pred).intersection({y_true}))) / p\n","\n","def recall(y_pred, y_true):\n","    return len(set(y_pred).intersection({y_true}))/len({y_true})\n","\n","def mrr(y_pred, y_true):\n","    for i in range(len(y_pred)):\n","        if y_pred[i] == y_true:\n","            return 1 / (y_pred.index(y_true) + 1)\n","    return 0\n","\n","def map_k(y_pred, y_true):\n","    relevances = []\n","    precisions = []\n","\n","    for i in range(len(y_pred)):\n","        if y_pred[i] == y_true:\n","            relevances.append(1)\n","            precisions.append(sum(relevances)/(i + 1))\n","    \n","    if len(precisions) > 0:\n","        return np.mean(precisions)\n","    \n","    return 0\n","\n","def ndcg(y_pred, y_true):\n","    if y_true in y_pred:\n","        index = y_pred.index(y_true)\n","        return np.reciprocal(np.log2(index + 2))\n","    return 0\n","\n","@torch.no_grad()\n","def metrics(model, test_loader, criterion, top_k, device):\n","    _hr, _precision, _recall, _mrr, _map, _ndcg = [], [], [], [], [], []\n","\n","    test_loss = []\n","    for user, item, label in test_loader:\n","        user = user.to(device)\n","        item = item.to(device)\n","        label = label.to(device)\n","\n","        predictions = model(user, item)\n","        predictions = predictions.view(-1)\n","        loss = criterion(predictions.to(torch.float64), \n","                            label.to(torch.float64))\n","        _, indices = torch.topk(predictions, top_k)\n","        recommends = torch.take(item, indices).cpu().numpy().tolist()\n","\n","        y_true = item[0].item()\n","        _hr.append(hit(recommends, y_true))\n","        _precision.append(precision(recommends, y_true))\n","        _recall.append(recall(recommends, y_true))\n","        _mrr.append(mrr(recommends, y_true))\n","        _map.append(map_k(recommends, y_true))\n","        _ndcg.append(ndcg(recommends, y_true))\n","        test_loss.append(loss.cpu().numpy())\n","    \n","    return np.mean(test_loss), np.mean(_hr), np.mean(_precision), np.mean(_recall), np.mean(_mrr), np.mean(_map), np.mean(_ndcg)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Архитектура (GMF)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:54.644269Z","iopub.status.busy":"2023-05-14T22:16:54.643819Z","iopub.status.idle":"2023-05-14T22:16:54.658318Z","shell.execute_reply":"2023-05-14T22:16:54.657238Z","shell.execute_reply.started":"2023-05-14T22:16:54.644235Z"},"trusted":true},"outputs":[],"source":["class GMF(nn.Module):\n","    def __init__(self, num_users, num_items, embedding_dim):\n","        super(GMF, self).__init__()\n","        self.num_users = num_users+1\n","        self.num_items = num_items+1\n","        self.embedding_dim = embedding_dim\n","\n","        self.embedding_user = nn.Embedding(\n","            num_embeddings=num_users+1, \n","            embedding_dim=embedding_dim)\n","        self.embedding_item = nn.Embedding(\n","            num_embeddings=num_items+1,\n","            embedding_dim=embedding_dim\n","        )\n","\n","        self.affine_output = nn.Linear(\n","            in_features=embedding_dim,\n","            out_features=1\n","        )\n","        self.activation = nn.Sigmoid()\n","\n","        nn.init.xavier_uniform_(self.embedding_user.weight)\n","        nn.init.xavier_uniform_(self.embedding_item.weight)\n","\n","    def forward(self, user_indices, item_indeces):\n","        user_embedding = self.embedding_user(user_indices)\n","        item_embedding = self.embedding_item(item_indeces)\n","        element_product = torch.mul(user_embedding,\n","                                    item_embedding)\n","        logits = self.affine_output(element_product)\n","        rating = self.activation(logits)\n","        return rating"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:54.661178Z","iopub.status.busy":"2023-05-14T22:16:54.660686Z","iopub.status.idle":"2023-05-14T22:16:54.673448Z","shell.execute_reply":"2023-05-14T22:16:54.672463Z","shell.execute_reply.started":"2023-05-14T22:16:54.661146Z"},"trusted":true},"outputs":[],"source":["def train_pipeline(model,\n","                   optimizer,\n","                   criterion,\n","                   data,\n","                   num_epoch):\n","    loss_history_epoch = []\n","    metrics_history = {\"Test_loss\": [], \"HR@10\": [], \"Precision@10\": [], \"Recall@10\": [],\n","                      \"MRR@10\": [], \"MAP@10\": [], \"NDCG@10\": []}\n","    test_loader = data.get_test_instance()\n","    \n","    for epoch in trange(num_epoch):\n","        loss_history = []\n","        model.train()\n","        \n","        train_loader = data.get_train_instance()\n","\n","        for user, item, label in train_loader:\n","            user = user.to(DEVICE)\n","            item = item.to(DEVICE)\n","            label = label.to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            prediction = model(user, item)\n","            \n","            loss = criterion(prediction.view(-1).to(torch.float64), \n","                            label.to(torch.float64))\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_history.append(loss.item())\n","\n","        model.eval()\n","        test_loss, hr_i, precision_i, recall_i, mrr_i, map_i, ndcg_i = metrics(model, test_loader, criterion, 10, DEVICE)\n","        metrics_history['Test_loss'].append(test_loss)\n","        metrics_history['HR@10'].append(hr_i)\n","        metrics_history['Precision@10'].append(precision_i)\n","        metrics_history['Recall@10'].append(recall_i)\n","        metrics_history['MRR@10'].append(mrr_i)\n","        metrics_history['MAP@10'].append(map_i)\n","        metrics_history['NDCG@10'].append(ndcg_i)\n","        loss_history_epoch.append(np.mean(loss_history))\n","\n","        print(f\"[Epoch {epoch}]| Loss train: {loss_history_epoch[-1]:.5f}\\tLoss test: {test_loss}\\n\"\\\n","              f\"HR@10: {hr_i:.3f}\\tPrecision@10: {precision_i:.3f}\\tRecall@10: {recall_i:.3f}\\t\"\\\n","             f\"MRR@10: {mrr_i:.3f}\\tMAP@10: {map_i:.3f}\\tNDCG@10 {ndcg_i:.3f} |\")\n","\n","    return loss_history_epoch, metrics_history"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:54.675234Z","iopub.status.busy":"2023-05-14T22:16:54.674802Z","iopub.status.idle":"2023-05-14T22:16:57.730740Z","shell.execute_reply":"2023-05-14T22:16:57.729748Z","shell.execute_reply.started":"2023-05-14T22:16:54.675182Z"},"trusted":true},"outputs":[],"source":["model = GMF(num_users=num_users, num_items=num_items, embedding_dim=32)\n","model.to(DEVICE)\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T22:16:57.732370Z","iopub.status.busy":"2023-05-14T22:16:57.732000Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a22426bb5399484c82216fea933acf76","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6040 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40c140dd404a40ebb5786f1e5fa2211c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[Epoch 0]| Loss train: 0.56520\tLoss test: 0.49669503982055185\n","HR@10: 0.403\tPrecision@10: 0.040\tRecall@10: 0.403\tMRR@10: 0.134\tMAP@10: 0.134\tNDCG@10 0.196 |\n","[Epoch 1]| Loss train: 0.45654\tLoss test: 0.4653061244461654\n","HR@10: 0.436\tPrecision@10: 0.044\tRecall@10: 0.436\tMRR@10: 0.150\tMAP@10: 0.150\tNDCG@10 0.216 |\n","[Epoch 2]| Loss train: 0.41397\tLoss test: 0.42154212065861746\n","HR@10: 0.461\tPrecision@10: 0.046\tRecall@10: 0.461\tMRR@10: 0.155\tMAP@10: 0.155\tNDCG@10 0.226 |\n","[Epoch 3]| Loss train: 0.38513\tLoss test: 0.38625855889055455\n","HR@10: 0.484\tPrecision@10: 0.048\tRecall@10: 0.484\tMRR@10: 0.162\tMAP@10: 0.162\tNDCG@10 0.236 |\n","[Epoch 4]| Loss train: 0.36867\tLoss test: 0.3664403258257675\n","HR@10: 0.497\tPrecision@10: 0.050\tRecall@10: 0.497\tMRR@10: 0.165\tMAP@10: 0.165\tNDCG@10 0.242 |\n","[Epoch 5]| Loss train: 0.35368\tLoss test: 0.3495251644867044\n","HR@10: 0.511\tPrecision@10: 0.051\tRecall@10: 0.511\tMRR@10: 0.168\tMAP@10: 0.168\tNDCG@10 0.247 |\n","[Epoch 6]| Loss train: 0.34198\tLoss test: 0.3382027260943466\n","HR@10: 0.517\tPrecision@10: 0.052\tRecall@10: 0.517\tMRR@10: 0.171\tMAP@10: 0.171\tNDCG@10 0.251 |\n","[Epoch 7]| Loss train: 0.33418\tLoss test: 0.33004630966692755\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.175\tMAP@10: 0.175\tNDCG@10 0.256 |\n","[Epoch 8]| Loss train: 0.32759\tLoss test: 0.3215857720645054\n","HR@10: 0.529\tPrecision@10: 0.053\tRecall@10: 0.529\tMRR@10: 0.174\tMAP@10: 0.174\tNDCG@10 0.256 |\n","[Epoch 9]| Loss train: 0.32146\tLoss test: 0.31798156965070684\n","HR@10: 0.531\tPrecision@10: 0.053\tRecall@10: 0.531\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.259 |\n","[Epoch 10]| Loss train: 0.31729\tLoss test: 0.3147959400270799\n","HR@10: 0.531\tPrecision@10: 0.053\tRecall@10: 0.531\tMRR@10: 0.176\tMAP@10: 0.176\tNDCG@10 0.258 |\n","[Epoch 11]| Loss train: 0.31250\tLoss test: 0.3092251717962047\n","HR@10: 0.536\tPrecision@10: 0.054\tRecall@10: 0.536\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.260 |\n","[Epoch 12]| Loss train: 0.30816\tLoss test: 0.30633413767246703\n","HR@10: 0.534\tPrecision@10: 0.053\tRecall@10: 0.534\tMRR@10: 0.176\tMAP@10: 0.176\tNDCG@10 0.259 |\n","[Epoch 13]| Loss train: 0.30338\tLoss test: 0.30212070960833753\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.263 |\n","[Epoch 14]| Loss train: 0.29846\tLoss test: 0.29957014805951787\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.262 |\n","[Epoch 15]| Loss train: 0.29378\tLoss test: 0.29597812347390984\n","HR@10: 0.543\tPrecision@10: 0.054\tRecall@10: 0.543\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.263 |\n","[Epoch 16]| Loss train: 0.28979\tLoss test: 0.2922921738902082\n","HR@10: 0.551\tPrecision@10: 0.055\tRecall@10: 0.551\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.268 |\n","[Epoch 17]| Loss train: 0.28532\tLoss test: 0.2925339932864427\n","HR@10: 0.545\tPrecision@10: 0.055\tRecall@10: 0.545\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.264 |\n","[Epoch 18]| Loss train: 0.28146\tLoss test: 0.29159026286508294\n","HR@10: 0.551\tPrecision@10: 0.055\tRecall@10: 0.551\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.267 |\n","[Epoch 19]| Loss train: 0.27841\tLoss test: 0.2879344166870061\n","HR@10: 0.549\tPrecision@10: 0.055\tRecall@10: 0.549\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.266 |\n","[Epoch 20]| Loss train: 0.27612\tLoss test: 0.2858541907418582\n","HR@10: 0.548\tPrecision@10: 0.055\tRecall@10: 0.548\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.267 |\n","[Epoch 21]| Loss train: 0.27290\tLoss test: 0.2886614834050938\n","HR@10: 0.545\tPrecision@10: 0.055\tRecall@10: 0.545\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.264 |\n","[Epoch 22]| Loss train: 0.27230\tLoss test: 0.2859263162267113\n","HR@10: 0.549\tPrecision@10: 0.055\tRecall@10: 0.549\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.265 |\n","[Epoch 23]| Loss train: 0.26988\tLoss test: 0.2863188956518554\n","HR@10: 0.554\tPrecision@10: 0.055\tRecall@10: 0.554\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.268 |\n","[Epoch 24]| Loss train: 0.26804\tLoss test: 0.2876048828777303\n","HR@10: 0.546\tPrecision@10: 0.055\tRecall@10: 0.546\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.265 |\n","[Epoch 25]| Loss train: 0.26792\tLoss test: 0.2850734202673242\n","HR@10: 0.546\tPrecision@10: 0.055\tRecall@10: 0.546\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.264 |\n","[Epoch 26]| Loss train: 0.26678\tLoss test: 0.2847995972144963\n","HR@10: 0.546\tPrecision@10: 0.055\tRecall@10: 0.546\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.264 |\n","[Epoch 27]| Loss train: 0.26550\tLoss test: 0.28460200187741375\n","HR@10: 0.544\tPrecision@10: 0.054\tRecall@10: 0.544\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.263 |\n","[Epoch 28]| Loss train: 0.26453\tLoss test: 0.283611645054312\n","HR@10: 0.545\tPrecision@10: 0.055\tRecall@10: 0.545\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.263 |\n","[Epoch 29]| Loss train: 0.26343\tLoss test: 0.28489686518584384\n","HR@10: 0.545\tPrecision@10: 0.054\tRecall@10: 0.545\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.264 |\n","[Epoch 30]| Loss train: 0.26239\tLoss test: 0.2839009256984594\n","HR@10: 0.548\tPrecision@10: 0.055\tRecall@10: 0.548\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.266 |\n","[Epoch 31]| Loss train: 0.26188\tLoss test: 0.28392168873920437\n","HR@10: 0.546\tPrecision@10: 0.055\tRecall@10: 0.546\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.266 |\n","[Epoch 32]| Loss train: 0.26134\tLoss test: 0.28260073982945294\n","HR@10: 0.549\tPrecision@10: 0.055\tRecall@10: 0.549\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.266 |\n","[Epoch 33]| Loss train: 0.26057\tLoss test: 0.283369180419116\n","HR@10: 0.542\tPrecision@10: 0.054\tRecall@10: 0.542\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.264 |\n","[Epoch 34]| Loss train: 0.25960\tLoss test: 0.28412598703511704\n","HR@10: 0.543\tPrecision@10: 0.054\tRecall@10: 0.543\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.265 |\n","[Epoch 35]| Loss train: 0.25936\tLoss test: 0.28497074111682713\n","HR@10: 0.541\tPrecision@10: 0.054\tRecall@10: 0.541\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.263 |\n","[Epoch 36]| Loss train: 0.25947\tLoss test: 0.28317175141402096\n","HR@10: 0.544\tPrecision@10: 0.054\tRecall@10: 0.544\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.265 |\n","[Epoch 37]| Loss train: 0.25832\tLoss test: 0.2834681736085558\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.264 |\n","[Epoch 38]| Loss train: 0.25795\tLoss test: 0.28402725149778757\n","HR@10: 0.547\tPrecision@10: 0.055\tRecall@10: 0.547\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.265 |\n","[Epoch 39]| Loss train: 0.25795\tLoss test: 0.2836040699428065\n","HR@10: 0.543\tPrecision@10: 0.054\tRecall@10: 0.543\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.264 |\n","[Epoch 40]| Loss train: 0.25704\tLoss test: 0.28447283549775854\n","HR@10: 0.541\tPrecision@10: 0.054\tRecall@10: 0.541\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.264 |\n","[Epoch 41]| Loss train: 0.25625\tLoss test: 0.2853217773703574\n","HR@10: 0.543\tPrecision@10: 0.054\tRecall@10: 0.543\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.262 |\n","[Epoch 42]| Loss train: 0.25617\tLoss test: 0.28481400375296534\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.263 |\n","[Epoch 43]| Loss train: 0.25593\tLoss test: 0.28470685177793825\n","HR@10: 0.538\tPrecision@10: 0.054\tRecall@10: 0.538\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.264 |\n","[Epoch 44]| Loss train: 0.25585\tLoss test: 0.2847773471890409\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.265 |\n","[Epoch 45]| Loss train: 0.25567\tLoss test: 0.2848813250283988\n","HR@10: 0.540\tPrecision@10: 0.054\tRecall@10: 0.540\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.264 |\n","[Epoch 46]| Loss train: 0.25549\tLoss test: 0.2846520696802947\n","HR@10: 0.546\tPrecision@10: 0.055\tRecall@10: 0.546\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.266 |\n","[Epoch 47]| Loss train: 0.25502\tLoss test: 0.2838078331103146\n","HR@10: 0.538\tPrecision@10: 0.054\tRecall@10: 0.538\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.262 |\n","[Epoch 48]| Loss train: 0.25459\tLoss test: 0.28511987056112903\n","HR@10: 0.539\tPrecision@10: 0.054\tRecall@10: 0.539\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.263 |\n","[Epoch 49]| Loss train: 0.25417\tLoss test: 0.28558552107846835\n","HR@10: 0.537\tPrecision@10: 0.054\tRecall@10: 0.537\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.263 |\n"]}],"source":["loss_history, metrics_history = train_pipeline(model, optimizer, criterion, data, 50)"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["gmf = data2excel(\"gmf_1m_4negatives_100negativtest\", loss_history, metrics_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gmf[[\"HR@10\", \"MRR@10\", \"NDCG@10\"]].plot()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Архитектура MLP"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self,\n","                 num_users,\n","                 num_items,\n","                 embedding_dim,\n","                 layers):\n","        super(MLP, self).__init__()\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.embeddings_dim = embedding_dim\n","        self.layers = layers\n","\n","        self.embedding_user = nn.Embedding(\n","            num_embeddings=self.num_users,\n","            embedding_dim=self.embeddings_dim\n","        )\n","        self.embedding_item = nn.Embedding(\n","            num_embeddings=self.num_items,\n","            embedding_dim=self.embeddings_dim\n","        )\n","        \n","        self.fc1 = nn.Linear(self.embeddings_dim * 2, layers[0])\n","        self.fc2 = nn.Linear(layers[0], layers[1])\n","        self.fc3 = nn.Linear(layers[1], layers[2])\n","        self.fc4 = nn.Linear(layers[2], layers[3])\n","        self.fc5 = nn.Linear(layers[3], layers[4])\n","        self.fc6 = nn.Linear(layers[4], layers[5])\n","\n","        self.affine_output = nn.Linear(self.layers[-1], 1)\n","        self.activation_layer = nn.ReLU()\n","        self.activation = nn.Sigmoid()\n","\n","        nn.init.xavier_uniform_(self.embedding_user.weight)\n","        nn.init.xavier_uniform_(self.embedding_item.weight)\n","\n","    def forward(self, user_indices, item_indices):\n","        user_embedding = self.embedding_user(user_indices)\n","        item_embedding = self.embedding_item(item_indices)\n","        element_concat = torch.cat((user_embedding,\n","                                    item_embedding), -1)\n","        layer1 = self.activation_layer(self.fc1(element_concat))\n","        layer2 = self.activation_layer(self.fc2(layer1))\n","        layer3 = self.activation_layer(self.fc3(layer2))\n","        layer4 = self.activation_layer(self.fc4(layer3))\n","        layer5 = self.activation_layer(self.fc5(layer4))\n","        layer6 = self.activation_layer(self.fc6(layer5))\n","\n","        logits = self.affine_output(layer6)\n","        rating = self.activation(logits)\n","\n","        return rating\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = MLP(num_users=len(num_users),\n","            num_items=len(num_items),\n","            embedding_dim=128,\n","            layers=[128, 64, 32, 16, 8, 4])\n","model.to(DEVICE)\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["summary(model, [(128,), (128,)], dtypes=[torch.long, torch.long])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_history_mlp, metrics_history_mlp =\\\n","    train_pipeline(model, optimizer, criterion, data, 10)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### NeuMF"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["class NeuMF(nn.Module):\n","    def __init__(self,\n","                 num_users,\n","                 num_items,\n","                 embedding_dim,\n","                 layers,\n","                 layers_neumf):\n","        super(NeuMF, self).__init__()\n","\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.embedding_dim = embedding_dim\n","        self.layers = layers\n","        self.layers_neumf = layers_neumf\n","\n","        self.embedding_user_mlp = nn.Embedding(\n","            num_embeddings=self.num_users + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","        self.embedding_item_mlp = nn.Embedding(\n","            num_embeddings=self.num_items + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embedding_user_mf = nn.Embedding(\n","            num_embeddings=self.num_users + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","        self.embedding_item_mf = nn.Embedding(\n","            num_embeddings=self.num_items + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.embedding_dim * 2, self.layers[0]),\n","            nn.BatchNorm1d(self.layers[0]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers[0], self.layers[1]),\n","            nn.BatchNorm1d(self.layers[1]),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.4),\n","            nn.Linear(self.layers[1], self.layers[2]),\n","            nn.BatchNorm1d(self.layers[2]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers[2], self.layers[3]),\n","            nn.BatchNorm1d(self.layers[3]),\n","            nn.ReLU(),\n","        )\n","        \n","        self.fc_neumf = nn.Sequential(\n","            nn.Linear(self.layers[-1] + self.embedding_dim, self.layers_neumf[0]),\n","            nn.BatchNorm1d(self.layers_neumf[0]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers_neumf[0], self.layers_neumf[1]),\n","            nn.BatchNorm1d(self.layers_neumf[1]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers_neumf[1], self.layers_neumf[2]),\n","            nn.BatchNorm1d(self.layers_neumf[2]),\n","            nn.ReLU()\n","        )\n","        \n","        self.affine_output = nn.Linear(\n","            self.layers_neumf[-1], 1\n","        )\n","        \n","        self.activate = nn.Sigmoid()\n","        \n","        nn.init.xavier_uniform_(self.embedding_user_mlp.weight)\n","        nn.init.xavier_uniform_(self.embedding_item_mlp.weight)\n","\n","        nn.init.xavier_uniform_(self.embedding_user_mf.weight)\n","        nn.init.xavier_uniform_(self.embedding_item_mf.weight)\n","\n","    def forward(self, user_indices, item_indices):\n","        # Эмбеддинги для mlp\n","        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n","        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n","        # Эмбеддинги для mf\n","        user_embedding_mf = self.embedding_user_mf(user_indices)\n","        item_embedding_mf = self.embedding_item_mf(item_indices)\n","        \n","        \n","        element_product_mf = torch.mul(\n","            user_embedding_mf, item_embedding_mf\n","        )\n","        element_product_mlp = torch.cat(\n","            (user_embedding_mlp, item_embedding_mlp), -1\n","        )\n","\n","        layers_mlp = self.fc(element_product_mlp)\n","        \n","        layers_neumf = self.fc_neumf(torch.cat(\n","                (layers_mlp, element_product_mf), -1)\n","        )\n","        \n","        logits = self.affine_output(layers_neumf)\n","        rating = self.activate(logits)\n","\n","        return rating\n","        "]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["model = NeuMF(num_users=num_users,\n","              num_items=num_items,\n","              embedding_dim=64,\n","              layers=[1024, 512, 256, 128],\n","              layers_neumf=[512, 256, 128])\n","model.to(DEVICE)\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuMF(\n","  (embedding_user_mlp): Embedding(6041, 64)\n","  (embedding_item_mlp): Embedding(3707, 64)\n","  (embedding_user_mf): Embedding(6041, 64)\n","  (embedding_item_mf): Embedding(3707, 64)\n","  (fc): Sequential(\n","    (0): Linear(in_features=128, out_features=1024, bias=True)\n","    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=1024, out_features=512, bias=True)\n","    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.4, inplace=False)\n","    (7): Linear(in_features=512, out_features=256, bias=True)\n","    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Linear(in_features=256, out_features=128, bias=True)\n","    (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU()\n","  )\n","  (fc_neumf): Sequential(\n","    (0): Linear(in_features=192, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=512, out_features=256, bias=True)\n","    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=256, out_features=128, bias=True)\n","    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","  )\n","  (affine_output): Linear(in_features=128, out_features=1, bias=True)\n","  (activate): Sigmoid()\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5ec540b94d74d5d84433b690ca25281","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6040 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c5750f63b95406b8fdac6ef1cd81346","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[Epoch 0]| Loss train: 0.46898\tLoss test: 0.4243592038285913\n","HR@10: 0.459\tPrecision@10: 0.046\tRecall@10: 0.459\tMRR@10: 0.155\tMAP@10: 0.155\tNDCG@10 0.226 |\n","[Epoch 1]| Loss train: 0.35978\tLoss test: 0.34537911671803095\n","HR@10: 0.483\tPrecision@10: 0.048\tRecall@10: 0.483\tMRR@10: 0.157\tMAP@10: 0.157\tNDCG@10 0.232 |\n","[Epoch 2]| Loss train: 0.31101\tLoss test: 0.3043402291693356\n","HR@10: 0.511\tPrecision@10: 0.051\tRecall@10: 0.511\tMRR@10: 0.171\tMAP@10: 0.171\tNDCG@10 0.249 |\n","[Epoch 3]| Loss train: 0.28134\tLoss test: 0.33356872915537866\n","HR@10: 0.510\tPrecision@10: 0.051\tRecall@10: 0.510\tMRR@10: 0.168\tMAP@10: 0.168\tNDCG@10 0.247 |\n","[Epoch 4]| Loss train: 0.26290\tLoss test: 0.31869133977386355\n","HR@10: 0.526\tPrecision@10: 0.053\tRecall@10: 0.526\tMRR@10: 0.184\tMAP@10: 0.184\tNDCG@10 0.263 |\n","[Epoch 5]| Loss train: 0.24871\tLoss test: 0.3242532535298774\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.176\tMAP@10: 0.176\tNDCG@10 0.256 |\n","[Epoch 6]| Loss train: 0.23754\tLoss test: 0.3172112918062368\n","HR@10: 0.529\tPrecision@10: 0.053\tRecall@10: 0.529\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.261 |\n","[Epoch 7]| Loss train: 0.22836\tLoss test: 0.33622829240083535\n","HR@10: 0.518\tPrecision@10: 0.052\tRecall@10: 0.518\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.257 |\n","[Epoch 8]| Loss train: 0.22057\tLoss test: 0.34136649395736096\n","HR@10: 0.517\tPrecision@10: 0.052\tRecall@10: 0.517\tMRR@10: 0.174\tMAP@10: 0.174\tNDCG@10 0.254 |\n","[Epoch 9]| Loss train: 0.21390\tLoss test: 0.3499650470274943\n","HR@10: 0.527\tPrecision@10: 0.053\tRecall@10: 0.527\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.259 |\n","[Epoch 10]| Loss train: 0.20817\tLoss test: 0.35730920293056667\n","HR@10: 0.524\tPrecision@10: 0.052\tRecall@10: 0.524\tMRR@10: 0.175\tMAP@10: 0.175\tNDCG@10 0.256 |\n","[Epoch 11]| Loss train: 0.20294\tLoss test: 0.3786144367272553\n","HR@10: 0.531\tPrecision@10: 0.053\tRecall@10: 0.531\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.261 |\n","[Epoch 12]| Loss train: 0.19750\tLoss test: 0.38173712444463115\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.260 |\n","[Epoch 13]| Loss train: 0.19353\tLoss test: 0.38793988228794113\n","HR@10: 0.525\tPrecision@10: 0.053\tRecall@10: 0.525\tMRR@10: 0.177\tMAP@10: 0.177\tNDCG@10 0.257 |\n","[Epoch 14]| Loss train: 0.18895\tLoss test: 0.4031691969090193\n","HR@10: 0.522\tPrecision@10: 0.052\tRecall@10: 0.522\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.259 |\n","[Epoch 15]| Loss train: 0.18593\tLoss test: 0.41139675494678823\n","HR@10: 0.521\tPrecision@10: 0.052\tRecall@10: 0.521\tMRR@10: 0.177\tMAP@10: 0.177\tNDCG@10 0.257 |\n","[Epoch 16]| Loss train: 0.18276\tLoss test: 0.42023287048482355\n","HR@10: 0.518\tPrecision@10: 0.052\tRecall@10: 0.518\tMRR@10: 0.174\tMAP@10: 0.174\tNDCG@10 0.254 |\n","[Epoch 17]| Loss train: 0.17950\tLoss test: 0.41278464801657494\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.262 |\n","[Epoch 18]| Loss train: 0.17710\tLoss test: 0.4269464148078613\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.262 |\n","[Epoch 19]| Loss train: 0.17429\tLoss test: 0.45440461462797216\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.260 |\n","[Epoch 20]| Loss train: 0.17181\tLoss test: 0.43281765837855374\n","HR@10: 0.526\tPrecision@10: 0.053\tRecall@10: 0.526\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.261 |\n","[Epoch 21]| Loss train: 0.16956\tLoss test: 0.4746016411228501\n","HR@10: 0.517\tPrecision@10: 0.052\tRecall@10: 0.517\tMRR@10: 0.178\tMAP@10: 0.178\tNDCG@10 0.256 |\n","[Epoch 22]| Loss train: 0.16774\tLoss test: 0.47019810889036223\n","HR@10: 0.515\tPrecision@10: 0.052\tRecall@10: 0.515\tMRR@10: 0.175\tMAP@10: 0.175\tNDCG@10 0.254 |\n","[Epoch 23]| Loss train: 0.16483\tLoss test: 0.48282760415938447\n","HR@10: 0.525\tPrecision@10: 0.053\tRecall@10: 0.525\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.259 |\n","[Epoch 24]| Loss train: 0.16299\tLoss test: 0.4793660404176872\n","HR@10: 0.530\tPrecision@10: 0.053\tRecall@10: 0.530\tMRR@10: 0.184\tMAP@10: 0.184\tNDCG@10 0.264 |\n","[Epoch 25]| Loss train: 0.16064\tLoss test: 0.48856908768714274\n","HR@10: 0.527\tPrecision@10: 0.053\tRecall@10: 0.527\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.261 |\n","[Epoch 26]| Loss train: 0.15928\tLoss test: 0.48001248422248993\n","HR@10: 0.518\tPrecision@10: 0.052\tRecall@10: 0.518\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.259 |\n","[Epoch 27]| Loss train: 0.15772\tLoss test: 0.5054453889567666\n","HR@10: 0.535\tPrecision@10: 0.053\tRecall@10: 0.535\tMRR@10: 0.184\tMAP@10: 0.184\tNDCG@10 0.265 |\n","[Epoch 28]| Loss train: 0.15542\tLoss test: 0.49603286832477866\n","HR@10: 0.527\tPrecision@10: 0.053\tRecall@10: 0.527\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.260 |\n","[Epoch 29]| Loss train: 0.15504\tLoss test: 0.5410601813655335\n","HR@10: 0.527\tPrecision@10: 0.053\tRecall@10: 0.527\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.259 |\n","[Epoch 30]| Loss train: 0.15290\tLoss test: 0.5252227214148063\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.261 |\n","[Epoch 31]| Loss train: 0.15034\tLoss test: 0.5389718017259428\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.260 |\n","[Epoch 32]| Loss train: 0.14919\tLoss test: 0.5415880276880466\n","HR@10: 0.520\tPrecision@10: 0.052\tRecall@10: 0.520\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.258 |\n","[Epoch 33]| Loss train: 0.14868\tLoss test: 0.5498940155973582\n","HR@10: 0.526\tPrecision@10: 0.053\tRecall@10: 0.526\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.262 |\n","[Epoch 34]| Loss train: 0.14708\tLoss test: 0.5478580814516891\n","HR@10: 0.525\tPrecision@10: 0.053\tRecall@10: 0.525\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.261 |\n","[Epoch 35]| Loss train: 0.14589\tLoss test: 0.5757051952568109\n","HR@10: 0.530\tPrecision@10: 0.053\tRecall@10: 0.530\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.263 |\n","[Epoch 36]| Loss train: 0.14458\tLoss test: 0.5809878033054702\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.261 |\n","[Epoch 37]| Loss train: 0.14240\tLoss test: 0.5873906357825898\n","HR@10: 0.522\tPrecision@10: 0.052\tRecall@10: 0.522\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.260 |\n","[Epoch 38]| Loss train: 0.14176\tLoss test: 0.5812630903897873\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.262 |\n","[Epoch 39]| Loss train: 0.14064\tLoss test: 0.5713074025600606\n","HR@10: 0.518\tPrecision@10: 0.052\tRecall@10: 0.518\tMRR@10: 0.179\tMAP@10: 0.179\tNDCG@10 0.257 |\n","[Epoch 40]| Loss train: 0.13956\tLoss test: 0.6086763276180285\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.263 |\n","[Epoch 41]| Loss train: 0.13930\tLoss test: 0.6033360017244488\n","HR@10: 0.529\tPrecision@10: 0.053\tRecall@10: 0.529\tMRR@10: 0.184\tMAP@10: 0.184\tNDCG@10 0.264 |\n","[Epoch 42]| Loss train: 0.13684\tLoss test: 0.6042088791020405\n","HR@10: 0.523\tPrecision@10: 0.052\tRecall@10: 0.523\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.260 |\n","[Epoch 43]| Loss train: 0.13650\tLoss test: 0.601824398959725\n","HR@10: 0.530\tPrecision@10: 0.053\tRecall@10: 0.530\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.263 |\n","[Epoch 44]| Loss train: 0.13470\tLoss test: 0.6140457624124478\n","HR@10: 0.529\tPrecision@10: 0.053\tRecall@10: 0.529\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.261 |\n","[Epoch 45]| Loss train: 0.13390\tLoss test: 0.6306711911850367\n","HR@10: 0.520\tPrecision@10: 0.052\tRecall@10: 0.520\tMRR@10: 0.180\tMAP@10: 0.180\tNDCG@10 0.259 |\n","[Epoch 46]| Loss train: 0.13287\tLoss test: 0.6422231027175801\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.263 |\n","[Epoch 47]| Loss train: 0.13185\tLoss test: 0.6416055193560372\n","HR@10: 0.526\tPrecision@10: 0.053\tRecall@10: 0.526\tMRR@10: 0.182\tMAP@10: 0.182\tNDCG@10 0.262 |\n","[Epoch 48]| Loss train: 0.13064\tLoss test: 0.6368976764368975\n","HR@10: 0.525\tPrecision@10: 0.052\tRecall@10: 0.525\tMRR@10: 0.181\tMAP@10: 0.181\tNDCG@10 0.261 |\n","[Epoch 49]| Loss train: 0.12940\tLoss test: 0.6391169949912981\n","HR@10: 0.528\tPrecision@10: 0.053\tRecall@10: 0.528\tMRR@10: 0.183\tMAP@10: 0.183\tNDCG@10 0.263 |\n"]}],"source":["loss_history_neumf, metrics_history_neumf =\\\n","    train_pipeline(model, optimizer, criterion, data, 50)"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[],"source":["neumf = data2excel(\"neumf_1m_1024_4neg_100negtest\", loss_history_neumf, metrics_history_neumf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["neumf"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["------"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["class UserItemRatingDatasetUsers(Dataset):\n","    def __init__(self, user:list, item:list, rating:list, sex:list, age_group:list, occupation:list):\n","        super(UserItemRatingDatasetUsers, self).__init__()\n","        \n","        self.user = torch.tensor(user, dtype=torch.long)\n","        self.item = torch.tensor(item, dtype=torch.long)\n","        self.target = torch.tensor(rating, dtype=torch.float)\n","        \n","        self.sex = torch.tensor(sex, dtype=torch.long)\n","        self.age = torch.tensor(age_group, dtype=torch.long)\n","        self.occupation = torch.tensor(occupation, dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.target)\n","        \n","    def __getitem__(self, idx):\n","        return self.user[idx], self.item[idx], self.target[idx], self.sex[idx], self.age[idx], self.occupation[idx]\n"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["class NCFDataUsers(object):\n","    def __init__(self, \n","                 ratings, \n","                 num_negatives, \n","                 num_negatives_test, \n","                 batch_size: int):\n","        self.ratings = ratings\n","        self.num_negatives = num_negatives\n","        self.num_negatives_test = num_negatives_test\n","        self.batch_size = batch_size\n","\n","        self.preprocess_ratings = self._reindex(self.ratings)\n","        self.user_pool = set(self.ratings[\"user_id\"].unique())\n","        self.item_pool = set(self.ratings[\"item_id\"].unique())\n","        self.sex_poll = set(self.ratings[\"sex_encoded\"].unique())\n","        self.age_poll = set(self.ratings[\"age_group_encoded\"].unique())\n","        self.occupation_pool = set(self.ratings[\"occupation\"].unique())\n","\n","        self.train_ratings, self.test_ratings = self._leave_p_out(\n","            self.preprocess_ratings\n","        )\n","        self.negatives = self._negative_sampling(self.preprocess_ratings)\n","\n","    def _reindex(self, ratings):\n","        user = list(ratings[\"user_id\"].drop_duplicates())\n","        self.user2id = {w: i for i, w in enumerate(user)}\n","\n","        item = list(ratings[\"item_id\"].drop_duplicates())\n","        self.item2id = {w: i for i, w in enumerate(item)}\n","\n","        sex = list(ratings[\"sex_encoded\"].drop_duplicates())\n","        self.sex2id = {w: i for i, w in enumerate(sex)}\n","        age = list(ratings[\"age_group_encoded\"].drop_duplicates())\n","        self.age2id = {w: i for i, w in enumerate(age)}\n","        occupation = list(ratings[\"occupation\"].drop_duplicates())\n","        self.occupation2id = {w: i for i, w in enumerate(occupation)}\n","\n","        ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: self.user2id[x])\n","        ratings[\"item_id\"] = ratings[\"item_id\"].apply(lambda x: self.item2id[x])\n","        ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x > 0))\n","        ratings[\"sex_encoded\"] = ratings[\"sex_encoded\"].apply(lambda x: self.sex2id[x])\n","        ratings[\"age_group_encoded\"] = ratings[\"age_group_encoded\"].apply(lambda x: self.age2id[x])\n","        ratings[\"occupation\"] = ratings[\"occupation\"].apply(lambda x: self.occupation2id[x])\n","\n","        return ratings\n","\n","    def _leave_one_out(self, ratings):\n","        ratings[\"rank_latest\"] = ratings.groupby([\"user_id\"])[\"timestamp\"].rank(\n","            method=\"first\", ascending=False\n","        )\n","        test = ratings.loc[ratings[\"rank_latest\"] == 1]\n","        train = ratings.loc[ratings[\"rank_latest\"] > 1]\n","        \n","        return train[[\"user_id\", \"item_id\", \"rating\"]], test[[\"user_id\", \"item_id\", \"rating\"]]\n","    \n","    def _leave_p_out(self, ratings, p=10):\n","        ratings[\"rank_latest\"] = ratings.groupby([\"user_id\"])[\"timestamp\"].rank(\n","            method=\"first\", ascending=False\n","        )\n","        test = ratings.loc[ratings[\"rank_latest\"] < p+1]\n","        train = ratings.loc[ratings[\"rank_latest\"] > p]\n","        return (train[[\"user_id\", \"item_id\", \"rating\", \"sex_encoded\", \"age_group_encoded\", \"occupation\"]],\n","                 test[[\"user_id\", \"item_id\", \"rating\", \"sex_encoded\", \"age_group_encoded\", \"occupation\"]])\n","\n","    def _negative_sampling(self, ratings):\n","        interact_status = (\n","            ratings.groupby(by=['user_id', \"sex_encoded\", \"age_group_encoded\", \"occupation\"])['item_id']\n","            .apply(set)\n","            .reset_index()\n","            .rename(columns={'item_id': 'interacted_items'})\n","        )\n","\n","        interact_status[\"negative_samples\"] = [\n","            random.sample(\n","                self.item_pool - interact_status[\"interacted_items\"].iloc[i],\n","                self.num_negatives_test,\n","            )\n","            for i in range(interact_status[\"user_id\"].shape[0])\n","        ]\n","        \n","        return interact_status[[\"user_id\", \"negative_samples\", \"interacted_items\", \"sex_encoded\", \"age_group_encoded\", \"occupation\"]]\n","\n","    def get_train_instance(self):\n","        users, items, ratings = [], [], []        \n","        train_ratings_negatives = pd.DataFrame()\n","        train_ratings_negatives['user_id'] = self.negatives['user_id']\n","        train_ratings_negatives['sex_encoded'] = self.negatives['sex_encoded']\n","        train_ratings_negatives['age_group_encoded'] = self.negatives['age_group_encoded']\n","        train_ratings_negatives['occupation'] = self.negatives['occupation']\n","        train_ratings_negatives[\"negatives\"] = [\n","            random.sample(\n","                self.item_pool - self.negatives['interacted_items'].iloc[i],\n","                len(self.negatives['interacted_items'].iloc[i]) if len(self.item_pool) - 2 * len(self.negatives['interacted_items'].iloc[i]) > 0 else self.num_negatives,\n","            )\n","            for i in range(self.negatives['interacted_items'].shape[0])\n","        ]\n","\n","        train_ratings_negatives = train_ratings_negatives.explode(\"negatives\")\n","\n","        users = np.append(self.train_ratings[\"user_id\"], \n","                          train_ratings_negatives[\"user_id\"]).astype(np.int64)\n","        items = np.append(self.train_ratings[\"item_id\"], \n","                          train_ratings_negatives[\"negatives\"]).astype(np.int64)\n","        ratings = np.append(self.train_ratings[\"rating\"], \n","                            [0 for i in range(train_ratings_negatives.shape[0])]).astype(np.int64)\n","        \n","        sex = np.append(self.train_ratings[\"sex_encoded\"],\n","                        train_ratings_negatives[\"sex_encoded\"]).astype(np.int64)\n","        age = np.append(self.train_ratings[\"age_group_encoded\"],\n","                        train_ratings_negatives[\"age_group_encoded\"]).astype(np.int64)\n","        occupation = np.append(self.train_ratings[\"occupation\"],\n","                               train_ratings_negatives[\"occupation\"]).astype(np.int64)\n","        \n","        \n","        assert len(users) == len(items) and len(items) == len(ratings)\n","\n","        dataset = UserItemRatingDatasetUsers(user=users, item=items, rating=ratings, sex=sex,\n","                                             age_group=age, occupation=occupation)\n","        return DataLoader(\n","            dataset, batch_size=self.batch_size, shuffle=True, num_workers=4\n","        )\n","\n","    def get_test_instance(self, p=10):\n","        users, items, ratings, sex, age, occupation = [], [], [], [], [], []\n","        test_ratings = pd.merge(\n","            self.test_ratings,\n","            self.negatives[[\"user_id\", \"negative_samples\"]],\n","            on=\"user_id\",\n","        )\n","        \n","        for user in tqdm(np.unique(test_ratings['user_id'])):\n","            for row in (test_ratings.loc[test_ratings['user_id'] == user]).itertuples():\n","                users.append(int(row.user_id))\n","                items.append(int(row.item_id))\n","                ratings.append(float(row.rating))\n","                sex.append(int(row.sex_encoded))\n","                age.append(int(row.age_group_encoded))\n","                occupation.append(int(row.occupation))\n","            for item_negative in test_ratings.loc[test_ratings['user_id'] == user]['negative_samples'].iloc[0]:\n","                users.append(int(user))\n","                items.append(int(item_negative))\n","                ratings.append(float(0))\n","                sex.append(int(row.sex_encoded))\n","                age.append(int(row.age_group_encoded))\n","                occupation.append(int(row.occupation))\n","\n","        dataset = UserItemRatingDatasetUsers(user=users, item=items, rating=ratings, sex=sex,\n","                                             age_group=age, occupation=occupation)\n","        return DataLoader(\n","            dataset, batch_size=self.num_negatives_test+p, shuffle=False, num_workers=4\n","        )"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1193</td>\n","      <td>5.0</td>\n","      <td>978300760</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>661</td>\n","      <td>3.0</td>\n","      <td>978302109</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>914</td>\n","      <td>3.0</td>\n","      <td>978301968</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>3408</td>\n","      <td>4.0</td>\n","      <td>978300275</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2355</td>\n","      <td>5.0</td>\n","      <td>978824291</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1000204</th>\n","      <td>6040</td>\n","      <td>1091</td>\n","      <td>1.0</td>\n","      <td>956716541</td>\n","    </tr>\n","    <tr>\n","      <th>1000205</th>\n","      <td>6040</td>\n","      <td>1094</td>\n","      <td>5.0</td>\n","      <td>956704887</td>\n","    </tr>\n","    <tr>\n","      <th>1000206</th>\n","      <td>6040</td>\n","      <td>562</td>\n","      <td>5.0</td>\n","      <td>956704746</td>\n","    </tr>\n","    <tr>\n","      <th>1000207</th>\n","      <td>6040</td>\n","      <td>1096</td>\n","      <td>4.0</td>\n","      <td>956715648</td>\n","    </tr>\n","    <tr>\n","      <th>1000208</th>\n","      <td>6040</td>\n","      <td>1097</td>\n","      <td>4.0</td>\n","      <td>956715569</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000209 rows × 4 columns</p>\n","</div>"],"text/plain":["         user_id  item_id  rating  timestamp\n","0              1     1193     5.0  978300760\n","1              1      661     3.0  978302109\n","2              1      914     3.0  978301968\n","3              1     3408     4.0  978300275\n","4              1     2355     5.0  978824291\n","...          ...      ...     ...        ...\n","1000204     6040     1091     1.0  956716541\n","1000205     6040     1094     5.0  956704887\n","1000206     6040      562     5.0  956704746\n","1000207     6040     1096     4.0  956715648\n","1000208     6040     1097     4.0  956715569\n","\n","[1000209 rows x 4 columns]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["ml_10m"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>sex</th>\n","      <th>age_group</th>\n","      <th>occupation</th>\n","      <th>zip_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>M</td>\n","      <td>56</td>\n","      <td>16</td>\n","      <td>70072</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>55117</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>M</td>\n","      <td>45</td>\n","      <td>7</td>\n","      <td>02460</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>20</td>\n","      <td>55455</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id sex  age_group  occupation zip_code\n","0        1   F          1          10    48067\n","1        2   M         56          16    70072\n","2        3   M         25          15    55117\n","3        4   M         45           7    02460\n","4        5   M         25          20    55455"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["users = pd.read_csv(\"./ml-1m/users.dat\", sep='::', engine='python', encoding=\"ISO-8859-1\",\n","                    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"])\n","users.head()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["le = LabelEncoder()\n","users[\"sex_encoded\"] = le.fit_transform(users.sex)\n","users[\"age_group_encoded\"] = le.fit_transform(users.age_group)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>sex</th>\n","      <th>age_group</th>\n","      <th>occupation</th>\n","      <th>zip_code</th>\n","      <th>sex_encoded</th>\n","      <th>age_group_encoded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>M</td>\n","      <td>56</td>\n","      <td>16</td>\n","      <td>70072</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>55117</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>M</td>\n","      <td>45</td>\n","      <td>7</td>\n","      <td>02460</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>20</td>\n","      <td>55455</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6035</th>\n","      <td>6036</td>\n","      <td>F</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>32603</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6036</th>\n","      <td>6037</td>\n","      <td>F</td>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>76006</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6037</th>\n","      <td>6038</td>\n","      <td>F</td>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>14706</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>6038</th>\n","      <td>6039</td>\n","      <td>F</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>01060</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6039</th>\n","      <td>6040</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6040 rows × 7 columns</p>\n","</div>"],"text/plain":["      user_id sex  age_group  occupation zip_code  sex_encoded  \\\n","0           1   F          1          10    48067            0   \n","1           2   M         56          16    70072            1   \n","2           3   M         25          15    55117            1   \n","3           4   M         45           7    02460            1   \n","4           5   M         25          20    55455            1   \n","...       ...  ..        ...         ...      ...          ...   \n","6035     6036   F         25          15    32603            0   \n","6036     6037   F         45           1    76006            0   \n","6037     6038   F         56           1    14706            0   \n","6038     6039   F         45           0    01060            0   \n","6039     6040   M         25           6    11106            1   \n","\n","      age_group_encoded  \n","0                     0  \n","1                     6  \n","2                     2  \n","3                     4  \n","4                     2  \n","...                 ...  \n","6035                  2  \n","6036                  4  \n","6037                  6  \n","6038                  4  \n","6039                  2  \n","\n","[6040 rows x 7 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["users"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","      <th>sex</th>\n","      <th>age_group</th>\n","      <th>occupation</th>\n","      <th>zip_code</th>\n","      <th>sex_encoded</th>\n","      <th>age_group_encoded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1193</td>\n","      <td>5.0</td>\n","      <td>978300760</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>661</td>\n","      <td>3.0</td>\n","      <td>978302109</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>914</td>\n","      <td>3.0</td>\n","      <td>978301968</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>3408</td>\n","      <td>4.0</td>\n","      <td>978300275</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2355</td>\n","      <td>5.0</td>\n","      <td>978824291</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>48067</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1000204</th>\n","      <td>6040</td>\n","      <td>1091</td>\n","      <td>1.0</td>\n","      <td>956716541</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1000205</th>\n","      <td>6040</td>\n","      <td>1094</td>\n","      <td>5.0</td>\n","      <td>956704887</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1000206</th>\n","      <td>6040</td>\n","      <td>562</td>\n","      <td>5.0</td>\n","      <td>956704746</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1000207</th>\n","      <td>6040</td>\n","      <td>1096</td>\n","      <td>4.0</td>\n","      <td>956715648</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1000208</th>\n","      <td>6040</td>\n","      <td>1097</td>\n","      <td>4.0</td>\n","      <td>956715569</td>\n","      <td>M</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>11106</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000209 rows × 10 columns</p>\n","</div>"],"text/plain":["         user_id  item_id  rating  timestamp sex  age_group  occupation  \\\n","0              1     1193     5.0  978300760   F          1          10   \n","1              1      661     3.0  978302109   F          1          10   \n","2              1      914     3.0  978301968   F          1          10   \n","3              1     3408     4.0  978300275   F          1          10   \n","4              1     2355     5.0  978824291   F          1          10   \n","...          ...      ...     ...        ...  ..        ...         ...   \n","1000204     6040     1091     1.0  956716541   M         25           6   \n","1000205     6040     1094     5.0  956704887   M         25           6   \n","1000206     6040      562     5.0  956704746   M         25           6   \n","1000207     6040     1096     4.0  956715648   M         25           6   \n","1000208     6040     1097     4.0  956715569   M         25           6   \n","\n","        zip_code  sex_encoded  age_group_encoded  \n","0          48067            0                  0  \n","1          48067            0                  0  \n","2          48067            0                  0  \n","3          48067            0                  0  \n","4          48067            0                  0  \n","...          ...          ...                ...  \n","1000204    11106            1                  2  \n","1000205    11106            1                  2  \n","1000206    11106            1                  2  \n","1000207    11106            1                  2  \n","1000208    11106            1                  2  \n","\n","[1000209 rows x 10 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["ml_10m_users = pd.merge(ml_10m, users, on=\"user_id\")\n","ml_10m_users"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["data = NCFDataUsers(ml_10m_users, num_negatives=4, num_negatives_test=100, batch_size=512)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["class NeuMF(nn.Module):\n","    def __init__(self,\n","                 num_users,\n","                 num_items,\n","                 embedding_dim,\n","                 layers,\n","                 layers_neumf):\n","        super(NeuMF, self).__init__()\n","\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.embedding_dim = embedding_dim\n","        self.layers = layers\n","        self.layers_neumf = layers_neumf\n","\n","        self.embedding_user_mlp = nn.Embedding(\n","            num_embeddings=self.num_users + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","        self.embedding_item_mlp = nn.Embedding(\n","            num_embeddings=self.num_items + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embedding_user_mf = nn.Embedding(\n","            num_embeddings=self.num_users + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","        self.embedding_item_mf = nn.Embedding(\n","            num_embeddings=self.num_items + 1,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embeddings_sex = nn.Embedding(3, 2)\n","        self.embeddings_occupation = nn.Embedding(22, 11)\n","        self.embeddings_age_group = nn.Embedding(8, 4)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.embedding_dim * 2 + 2 + 11 + 4, self.layers[0]),\n","            nn.BatchNorm1d(self.layers[0]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers[0], self.layers[1]),\n","            nn.BatchNorm1d(self.layers[1]),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.15),\n","            nn.Linear(self.layers[1], self.layers[2]),\n","            nn.BatchNorm1d(self.layers[2]),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.15),\n","            nn.Linear(self.layers[2], self.layers[3]),\n","            nn.BatchNorm1d(self.layers[3]),\n","            nn.ReLU(),\n","        )\n","        \n","        self.fc_neumf = nn.Sequential(\n","            nn.Linear(self.layers[-1] + self.embedding_dim, self.layers_neumf[0]),\n","            nn.BatchNorm1d(self.layers_neumf[0]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers_neumf[0], self.layers_neumf[1]),\n","            nn.BatchNorm1d(self.layers_neumf[1]),\n","            nn.ReLU(),\n","            nn.Linear(self.layers_neumf[1], self.layers_neumf[2]),\n","            nn.BatchNorm1d(self.layers_neumf[2]),\n","            nn.ReLU()\n","        )\n","        \n","        self.affine_output = nn.Linear(\n","            self.layers_neumf[-1], 1\n","        )\n","        \n","        self.activate = nn.Sigmoid()\n","        \n","        nn.init.xavier_uniform_(self.embedding_user_mlp.weight)\n","        nn.init.xavier_uniform_(self.embedding_item_mlp.weight)\n","\n","        nn.init.xavier_uniform_(self.embedding_user_mf.weight)\n","        nn.init.xavier_uniform_(self.embedding_item_mf.weight)\n","\n","    def forward(self, user_indices, item_indices, sex_indices, age_group_indices, occupation_indices):\n","        # Эмбеддинги для mlp\n","        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n","        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n","        # Эмбеддинги для mf\n","        user_embedding_mf = self.embedding_user_mf(user_indices)\n","        item_embedding_mf = self.embedding_item_mf(item_indices)\n","\n","        user_embedding_sex = self.embeddings_sex(sex_indices)\n","        user_embedding_age_group = self.embeddings_age_group(age_group_indices)\n","        user_embedding_occupation = self.embeddings_occupation(occupation_indices)\n","\n","        user_features = torch.cat(\n","            (user_embedding_sex, user_embedding_age_group, user_embedding_occupation), -1\n","        )\n","        \n","        element_product_mf = torch.mul(\n","            user_embedding_mf, item_embedding_mf\n","        )\n","        element_product_mlp = torch.cat(\n","            (user_embedding_mlp, item_embedding_mlp, user_features), -1\n","        )\n","\n","        layers_mlp = self.fc(element_product_mlp)\n","        \n","        layers_neumf = self.fc_neumf(torch.cat(\n","                (layers_mlp, element_product_mf), -1)\n","        )\n","        \n","        logits = self.affine_output(layers_neumf)\n","        rating = self.activate(logits)\n","\n","        return rating\n","        "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def metrics_neumf(model, test_loader, criterion, top_k, device):\n","    _hr, _precision, _recall, _mrr, _map, _ndcg = [], [], [], [], [], []\n","\n","    test_loss = []\n","    for user, item, label, sex, age, occupation in test_loader:\n","        user = user.to(device)\n","        item = item.to(device)\n","        sex = sex.to(device)\n","        age = age.to(device)\n","        occupation = occupation.to(device)\n","        label = label.to(device)\n","\n","        predictions = model(user, item, sex, age, occupation)\n","        predictions = predictions.view(-1)\n","        loss = criterion(predictions.to(torch.float64), \n","                            label.to(torch.float64))\n","        _, indices = torch.topk(predictions, top_k)\n","        recommends = torch.take(item, indices).cpu().numpy().tolist()\n","\n","        y_true = item[0].item()\n","        _hr.append(hit(recommends, y_true))\n","        _precision.append(precision(recommends, y_true))\n","        _recall.append(recall(recommends, y_true))\n","        _mrr.append(mrr(recommends, y_true))\n","        _map.append(map_k(recommends, y_true))\n","        _ndcg.append(ndcg(recommends, y_true))\n","        test_loss.append(loss.cpu().numpy())\n","    \n","    return np.mean(test_loss), np.mean(_hr), np.mean(_precision), np.mean(_recall), np.mean(_mrr), np.mean(_map), np.mean(_ndcg)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["def train_pipeline_neumf(model,\n","                   optimizer,\n","                   criterion,\n","                   data,\n","                   num_epoch):\n","    loss_history_epoch = []\n","    metrics_history = {\"Test_loss\": [], \"HR@10\": [], \"Precision@10\": [], \"Recall@10\": [],\n","                      \"MRR@10\": [], \"MAP@10\": [], \"NDCG@10\": []}\n","    test_loader = data.get_test_instance()\n","    train_loader = data.get_train_instance()\n","\n","    sheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0001, \n","                                                   steps_per_epoch=len(train_loader), epochs=num_epoch)\n","\n","    for epoch in trange(num_epoch):\n","        loss_history = []\n","        model.train()\n","\n","        for user, item, label, sex, age, occupation in train_loader:\n","            user = user.to(DEVICE)\n","            item = item.to(DEVICE)\n","            sex = sex.to(DEVICE)\n","            age = age.to(DEVICE)\n","            occupation = occupation.to(DEVICE)\n","            label = label.to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            prediction = model(user, item, sex, age, occupation)\n","            \n","            loss = criterion(prediction.view(-1).to(torch.float64), \n","                            label.to(torch.float64))\n","            loss.backward()\n","            optimizer.step()\n","            sheduler.step()\n","\n","            loss_history.append(loss.item())\n","\n","        train_loader = data.get_train_instance()\n","\n","        model.eval()\n","        test_loss, hr_i, precision_i, recall_i, mrr_i, map_i, ndcg_i = metrics_neumf(model, test_loader, criterion, 10, DEVICE)\n","        metrics_history['Test_loss'].append(test_loss)\n","        metrics_history['HR@10'].append(hr_i)\n","        metrics_history['Precision@10'].append(precision_i)\n","        metrics_history['Recall@10'].append(recall_i)\n","        metrics_history['MRR@10'].append(mrr_i)\n","        metrics_history['MAP@10'].append(map_i)\n","        metrics_history['NDCG@10'].append(ndcg_i)\n","        loss_history_epoch.append(np.mean(loss_history))\n","\n","        print(f\"[Epoch {epoch}]| Loss train: {loss_history_epoch[-1]:.5f}\\tLoss test: {test_loss}\\n\"\\\n","              f\"HR@10: {hr_i:.3f}\\tPrecision@10: {precision_i:.3f}\\tRecall@10: {recall_i:.3f}\\t\"\\\n","             f\"MRR@10: {mrr_i:.3f}\\tMAP@10: {map_i:.3f}\\tNDCG@10 {ndcg_i:.3f} |\")\n","\n","    return loss_history_epoch, metrics_history"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["model = NeuMF(num_users=num_users,\n","              num_items=num_items,\n","              embedding_dim=64,\n","              layers=[1024, 512, 256, 128],\n","              layers_neumf=[512, 256, 128])\n","model.to(DEVICE)\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, amsgrad=True)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuMF(\n","  (embedding_user_mlp): Embedding(6041, 64)\n","  (embedding_item_mlp): Embedding(3707, 64)\n","  (embedding_user_mf): Embedding(6041, 64)\n","  (embedding_item_mf): Embedding(3707, 64)\n","  (embeddings_sex): Embedding(3, 2)\n","  (embeddings_occupation): Embedding(22, 11)\n","  (embeddings_age_group): Embedding(8, 4)\n","  (fc): Sequential(\n","    (0): Linear(in_features=145, out_features=1024, bias=True)\n","    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=1024, out_features=512, bias=True)\n","    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.15, inplace=False)\n","    (7): Linear(in_features=512, out_features=256, bias=True)\n","    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Dropout(p=0.15, inplace=False)\n","    (11): Linear(in_features=256, out_features=128, bias=True)\n","    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): ReLU()\n","  )\n","  (fc_neumf): Sequential(\n","    (0): Linear(in_features=192, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=512, out_features=256, bias=True)\n","    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=256, out_features=128, bias=True)\n","    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","  )\n","  (affine_output): Linear(in_features=128, out_features=1, bias=True)\n","  (activate): Sigmoid()\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c364aa4df849428a8efa6768294aa5ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6040 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e52fee727afa4531bf16075efc68b525","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_history, metrics_history \u001b[39m=\u001b[39m train_pipeline_neumf(model, optimizer, criterion, data, \u001b[39m20\u001b[39;49m)\n","Cell \u001b[0;32mIn[49], line 41\u001b[0m, in \u001b[0;36mtrain_pipeline_neumf\u001b[0;34m(model, optimizer, criterion, data, num_epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m train_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget_train_instance()\n\u001b[1;32m     40\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 41\u001b[0m test_loss, hr_i, precision_i, recall_i, mrr_i, map_i, ndcg_i \u001b[39m=\u001b[39m metrics_neumf(model, test_loader, criterion, \u001b[39m10\u001b[39;49m, DEVICE)\n\u001b[1;32m     42\u001b[0m metrics_history[\u001b[39m'\u001b[39m\u001b[39mTest_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(test_loss)\n\u001b[1;32m     43\u001b[0m metrics_history[\u001b[39m'\u001b[39m\u001b[39mHR@10\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(hr_i)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","Cell \u001b[0;32mIn[34], line 6\u001b[0m, in \u001b[0;36mmetrics_neumf\u001b[0;34m(model, test_loader, criterion, top_k, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m _hr, _precision, _recall, _mrr, _map, _ndcg \u001b[39m=\u001b[39m [], [], [], [], [], []\n\u001b[1;32m      5\u001b[0m test_loss \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m user, item, label, sex, age, occupation \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m      7\u001b[0m     user \u001b[39m=\u001b[39m user\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     item \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:307\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrebuild_storage_fd\u001b[39m(\u001b[39mcls\u001b[39m, df, size):\n\u001b[0;32m--> 307\u001b[0m     fd \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m    308\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         storage \u001b[39m=\u001b[39m storage_from_cache(\u001b[39mcls\u001b[39m, fd_id(fd))\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetach\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[39m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mwith\u001b[39;00m _resource_sharer\u001b[39m.\u001b[39;49mget_connection(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id) \u001b[39mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m reduction\u001b[39m.\u001b[39mrecv_handle(conn)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[39m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[39m=\u001b[39m Client(address, authkey\u001b[39m=\u001b[39;49mprocess\u001b[39m.\u001b[39;49mcurrent_process()\u001b[39m.\u001b[39;49mauthkey)\n\u001b[1;32m     87\u001b[0m c\u001b[39m.\u001b[39msend((key, os\u001b[39m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m c\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:509\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m authkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     answer_challenge(c, authkey)\n\u001b[0;32m--> 509\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    511\u001b[0m \u001b[39mreturn\u001b[39;00m c\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:740\u001b[0m, in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    738\u001b[0m connection\u001b[39m.\u001b[39msend_bytes(CHALLENGE \u001b[39m+\u001b[39m message)\n\u001b[1;32m    739\u001b[0m digest \u001b[39m=\u001b[39m hmac\u001b[39m.\u001b[39mnew(authkey, message, \u001b[39m'\u001b[39m\u001b[39mmd5\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdigest()\n\u001b[0;32m--> 740\u001b[0m response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mrecv_bytes(\u001b[39m256\u001b[39;49m)        \u001b[39m# reject large message\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m digest:\n\u001b[1;32m    742\u001b[0m     connection\u001b[39m.\u001b[39msend_bytes(WELCOME)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m maxlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m maxlength \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnegative maxlength\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes(maxlength)\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bad_message_length()\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["loss_history, metrics_history = train_pipeline_neumf(model, optimizer, criterion, data, 20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["neumf = data2excel(\"neumf_with_users_1m_1024_4neg_100negtest\", loss_history, metrics_history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
